{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41c4a0dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Tavily Configuration Loaded.\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# CELL 1: SETUP\n",
    "# ==========================================\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "from typing import List, Dict, Any\n",
    "from tavily import TavilyClient\n",
    "import time\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "# Load Key from Environment\n",
    "load_dotenv(override=True)\n",
    "TAVILY_API_KEY = os.environ.get(\"TAVILY_API_KEY\")\n",
    "\n",
    "# Search Parameters\n",
    "SEARCH_CONFIG = {\n",
    "    \"search_depth\": \"advanced\",      # Deep search for quality\n",
    "    \"topic\": \"general\",              # General knowledge\n",
    "    \"max_results\": 5,                # Top 5 sources\n",
    "    \"include_answer\": True,          # Get the AI-generated summary\n",
    "    \"include_raw_content\": True,     # Get full page text\n",
    "    \"include_images\": False,\n",
    "    \"chunks_per_source\": 3\n",
    "}\n",
    "\n",
    "# Processing Config\n",
    "MAX_RAW_CHARS = 4000  # Truncate raw content per source to avoid context overflow\n",
    "MODEL_NAME = \"llama-3.3-70b-versatile\" # 100k TPD\n",
    "# MODEL_NAME = \"openai/gpt-oss-120b\" # 200k TPD\n",
    "\n",
    "print(\"‚úÖ Tavily Configuration Loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6df2ca98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Tavily Advanced Scout Ready.\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# CELL 2: DEEP WEB SCOUT ENGINE (TAVILY)\n",
    "# ==========================================\n",
    "\n",
    "class DeepWebScout:\n",
    "    def __init__(self):\n",
    "        if not TAVILY_API_KEY:\n",
    "            raise ValueError(\"‚ùå TAVILY_API_KEY not found in environment variables.\")\n",
    "        self.client = TavilyClient(api_key=TAVILY_API_KEY)\n",
    "\n",
    "    def _clean_raw_content(self, text: str) -> str:\n",
    "        \"\"\"\n",
    "        Helper to clean and truncate the massive raw_content strings.\n",
    "        Removes excessive newlines and limits length.\n",
    "        \"\"\"\n",
    "        if not text: return \"\"\n",
    "        # Collapse whitespace\n",
    "        clean = re.sub(r'\\s+', ' ', text).strip()\n",
    "        # Truncate to keep context window healthy\n",
    "        if len(clean) > MAX_RAW_CHARS:\n",
    "            return clean[:MAX_RAW_CHARS] + \"... [TRUNCATED]\"\n",
    "        return clean\n",
    "\n",
    "    def search_and_extract(self, sub_query: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Executes Advanced Search and formats the JSON for the Agent/Curator.\n",
    "        \"\"\"\n",
    "        print(f\"   üîé Scouting External Cortex for: '{sub_query}'...\")\n",
    "        \n",
    "        try:\n",
    "            # 1. CALL TAVILY API\n",
    "            response = self.client.search(query=sub_query, **SEARCH_CONFIG)\n",
    "            \n",
    "            # 2. EXTRACT THE \"ADVANCED ANSWER\" (The Executive Summary)\n",
    "            # Tavily's LLM generates this based on the search results.\n",
    "            # This is extremely high-value for our Storyteller/Synthesizer.\n",
    "            ai_summary = response.get(\"answer\", \"\")\n",
    "            \n",
    "            # 3. PROCESS THE EVIDENCE (The \"Results\" List)\n",
    "            results = response.get(\"results\", [])\n",
    "            \n",
    "            formatted_context = []\n",
    "            curation_data = []\n",
    "            \n",
    "            # If we have an AI summary, put it at the very top of the context\n",
    "            if ai_summary:\n",
    "                formatted_context.append(f\"‚òÖ EXECUTIVE SUMMARY (AI GENERATED):\\n{ai_summary}\\n{'-'*40}\")\n",
    "\n",
    "            print(f\"   üëÄ Retrieved {len(results)} high-fidelity sources...\")\n",
    "            \n",
    "            for i, res in enumerate(results):\n",
    "                # Extract Metadata\n",
    "                title = res.get(\"title\", \"Unknown Title\")\n",
    "                url = res.get(\"url\", \"No URL\")\n",
    "                score = res.get(\"score\", 0.0)\n",
    "                \n",
    "                # We prefer the high-quality snippet 'content', but we back it up\n",
    "                # with 'raw_content' if the snippet is too short.\n",
    "                snippet = res.get(\"content\", \"\")\n",
    "                raw_text = self._clean_raw_content(res.get(\"raw_content\", \"\"))\n",
    "                \n",
    "                # 4. CONSTRUCT CONTEXT STRING (For the Agent)\n",
    "                # We prioritize the Title/URL/Snippet.\n",
    "                # We append a chunk of raw text only if it adds value.\n",
    "                entry = (\n",
    "                    f\"SOURCE [{i+1}]: {title}\\n\"\n",
    "                    f\"LINK: {url} (Relevance: {score:.2f})\\n\"\n",
    "                    f\"SUMMARY: {snippet}\\n\"\n",
    "                    f\"EXTRACT: {raw_text[:500]}...\\n\" # Give agent a peek at raw text\n",
    "                    f\"{'-'*40}\"\n",
    "                )\n",
    "                formatted_context.append(entry)\n",
    "                \n",
    "                # 5. PREPARE CURATION OBJECT (For the JSON File)\n",
    "                # The Curator gets the FULL raw text to extract graph triples.\n",
    "                curation_data.append({\n",
    "                    \"url\": url,\n",
    "                    \"title\": title,\n",
    "                    \"relevance_score\": score,\n",
    "                    \"snippet\": snippet,\n",
    "                    \"full_text\": raw_text # Curator gets the big chunk\n",
    "                })\n",
    "\n",
    "            return {\n",
    "                \"status\": \"success\",\n",
    "                \"tavily_answer\": ai_summary,      # The direct answer\n",
    "                \"agent_context\": \"\\n\".join(formatted_context), # The string for the Prompt\n",
    "                \"curation_data\": curation_data,   # The list for the JSON file\n",
    "                \"original_response\": response     # Keep full metadata just in case\n",
    "            }\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Search Engine Error: {e}\")\n",
    "            return {\"status\": \"failed\", \"content\": str(e)}\n",
    "\n",
    "# Initialize\n",
    "scout = DeepWebScout()\n",
    "print(\"üöÄ Tavily Advanced Scout Ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b0a5e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìö Curator Ready.\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# CELL 3: KNOWLEDGE CURATOR (UPDATED)\n",
    "# ==========================================\n",
    "class KnowledgeCurator:\n",
    "    def __init__(self, pending_file=\"./models/pending_knowledge.json\", model_name=\"llama-3.3-70b-versatile\"):\n",
    "        self.pending_file = pending_file\n",
    "        self.llm = ChatGroq(\n",
    "            temperature=0, \n",
    "            model_name=model_name, \n",
    "            api_key=os.environ.get(\"GROQ_API_KEY\"),\n",
    "            model_kwargs={\"response_format\": {\"type\": \"json_object\"}}\n",
    "        )\n",
    "\n",
    "    def curate(self, query: str, scout_result: Dict):\n",
    "        \"\"\"\n",
    "        Takes the scout result, analyzes the 'curation_data', and saves a knowledge artifact.\n",
    "        \"\"\"\n",
    "        if scout_result[\"status\"] != \"success\":\n",
    "            return\n",
    "\n",
    "        print(\"   üß† Curating knowledge from raw content...\")\n",
    "        \n",
    "        # Prepare a rich context from the top 3 results for the Curator\n",
    "        # We combine the raw text from the best sources\n",
    "        best_sources = scout_result[\"curation_data\"][:3] \n",
    "        combined_text = \"\\n\\n\".join([f\"Source ({s['url']}): {s['full_text']}\" for s in best_sources])\n",
    "        \n",
    "        sys_msg = \"\"\"\n",
    "            You are the **Graph RAG Knowledge Architect**.\n",
    "            Your goal is to transform raw, noisy web content into a pristine, structured Knowledge Artifact optimized for both vector search and graph traversal.\n",
    "\n",
    "            ### INSTRUCTIONS\n",
    "\n",
    "            1. **VECTOR CONTENT (The Summary)**:\n",
    "            - Synthesize a **dense, information-rich paragraph** that directly answers the User Query based *only* on the Scraped Content.\n",
    "            - Remove conversational fluff (\"The article states...\", \"It is important to note...\").\n",
    "            - Focus on factual density: include dates, numbers, names, and specific technical details.\n",
    "            - This text will be embedded; ensure it is semantically complete and self-contained.\n",
    "\n",
    "            2. **GRAPH TRIPLES (The Knowledge Graph)**:\n",
    "            - Extract 5-15 semantic triples: `{\"head\": \"Subject\", \"relation\": \"Predicate\", \"tail\": \"Object\"}`.\n",
    "            - **Entity Rules (Head/Tail)**: Use precise Proper Nouns or technical concepts. Keep them atomic (e.g., \"Elon Musk\" instead of \"The CEO of Tesla Elon Musk\").\n",
    "            - **Relation Rules**: Use active, directed verbs (e.g., \"founded\", \"acquired\", \"located_in\", \"author_of\"). Avoid generic relations like \"is\" or \"has\" if a more specific one exists.\n",
    "            - **Canonicalization**: Resolve pronouns and aliases to their full names (e.g., replace \"he\" with the person's name).\n",
    "\n",
    "            3. **METADATA**:\n",
    "            - `confidence_score`: 0.0 (Irrelevant/Garbage) to 1.0 (Perfect, Factual Match).\n",
    "            - `category`: Classify the content into one specific domain tag (e.g., \"Market Data\", \"Technical Documentation\", \"Biography\", \"News\").\n",
    "\n",
    "            ### OUTPUT SCHEMA (Strict JSON)\n",
    "            {\n",
    "                \"vector_content\": \"Dense text summary...\",\n",
    "                \"graph_triples\": [\n",
    "                    {\"head\": \"Entity A\", \"relation\": \"relationship_verb\", \"tail\": \"Entity B\"},\n",
    "                    {\"head\": \"Entity B\", \"relation\": \"relationship_verb\", \"tail\": \"Entity C\"}\n",
    "                ],\n",
    "                \"metadata\": {\n",
    "                    \"confidence_score\": 0.85,\n",
    "                    \"category\": \"Domain Tag\"\n",
    "                }\n",
    "            }\n",
    "            \"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = self.llm.invoke([\n",
    "                SystemMessage(content=sys_msg),\n",
    "                HumanMessage(content=f\"QUERY: {query}\\n\\nCONTENT:\\n{combined_text[:6000]}\") # Context limit\n",
    "            ])\n",
    "            artifact_data = json.loads(response.content)\n",
    "            \n",
    "            final_artifact = {\n",
    "                \"status\": \"pending_review\",\n",
    "                \"timestamp\": time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "                \"original_query\": query,\n",
    "                \"data\": artifact_data\n",
    "            }\n",
    "            \n",
    "            self._save(final_artifact)\n",
    "            print(f\"   üíæ Knowledge Artifact Saved to {self.pending_file}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Curation Failed: {e}\")\n",
    "\n",
    "    def _save(self, artifact):\n",
    "        data = []\n",
    "        if os.path.exists(self.pending_file):\n",
    "            try:\n",
    "                with open(self.pending_file, \"r\") as f: data = json.load(f)\n",
    "            except: data = []\n",
    "        data.append(artifact)\n",
    "        with open(self.pending_file, \"w\") as f: json.dump(data, f, indent=2)\n",
    "\n",
    "curator = KnowledgeCurator(model_name=MODEL_NAME)\n",
    "print(\"üìö Curator Ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a0414ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üö® RAG GAP DETECTED. ACTIVATING EXTERNAL CORTEX.\n",
      "============================================================\n",
      "\n",
      "üåê TASK: current net worth Beyonce 2025\n",
      "   üîé Scouting External Cortex for: 'current net worth Beyonce 2025'...\n",
      "   üëÄ Retrieved 5 high-fidelity sources...\n",
      "\n",
      "üìÑ AGENT CONTEXT BLOCK (Preview):\n",
      "----------------------------------------\n",
      "‚òÖ EXECUTIVE SUMMARY (AI GENERATED):\n",
      "Beyonc√©'s net worth is estimated to be around $1 billion in 2025. She became the fifth billionaire musician, recognized by Forbes. Her success spans music, fashion, and business ventures.\n",
      "----------------------------------------\n",
      "SOURCE [1]: Beyonc√© declared a billionaire by Forbes - BBC\n",
      "LINK: https://www.bbc.com/news/articles/cn09091zw34o (Relevance: 1.00)\n",
      "SUMMARY: Earlier this month, Forbes estimated Beyonc√©'s net worth of $800m (¬£593m) and predicted she would cross the billionaire threshold for the first time following years of success.\n",
      "\n",
      "Her 2023 Renaissance World Tour grossed nearly $600m, making her one of the biggest pop music icons in the world alongside Taylor Swift. [...] But Forbes has disputed this figure, instead estimating Gomez to be worth $700m (¬£518m).\n",
      "\n",
      "## Beyonc√© reunites Destiny's Child at final Cowboy Carter show\n",
      "\n",
      "## Grammy Awards 2025: Beyonc√© finally wins best album\n",
      "\n",
      "Billionaires\n",
      "\n",
      "Beyonc√©\n",
      "\n",
      "United States\n",
      "\n",
      "Music\n",
      "\n",
      "--- [...] Skip to content\n",
      "\n",
      "Watch Live\n",
      "\n",
      "Watch Live\n",
      "\n",
      "# Beyonc√© declared a billionaire by Forbes\n",
      "\n",
      "Pritti MistryBusiness reporter\n",
      "\n",
      "Beyonc√© has been declared a billionaire by Forbes, making her the fifth musician to join its list of the world's wealthiest people.\n",
      "\n",
      "The American star has joined an elite group of musicians with 10-figure fortunes, Forbes reports, including Taylor Swift, Rihanna, Bruce Springsteen and her husband Jay-Z, who the business magazine lists as having a net worth of $2.5bn (¬£1.85bn).\n",
      "EXTRACT: [Skip to content](#main-content) [Watch Live](/watch-live-news/) [Watch Live](/watch-live-news/) # Beyonc√© declared a billionaire by Forbes Pritti MistryBusiness reporter Beyonc√© has been declared a billionaire by Forbes, making her the fifth musician to join its list of the world's wealthiest people. The American star has joined an elite group of musicians with 10-figure fortunes, Forbes reports, including Taylor Swift, Rihanna, Bruce Springsteen and her husband Jay-Z, who the business magazine......\n",
      "[Truncated for view]\n",
      "   üß† Curating knowledge from raw content...\n",
      "   üíæ Knowledge Artifact Saved to ./models/pending_knowledge.json\n",
      "------------------------------------------------------------\n",
      "\n",
      "üåê TASK: Beyonce recent tour gross earnings 2024\n",
      "   üîé Scouting External Cortex for: 'Beyonce recent tour gross earnings 2024'...\n",
      "   üëÄ Retrieved 5 high-fidelity sources...\n",
      "\n",
      "üìÑ AGENT CONTEXT BLOCK (Preview):\n",
      "----------------------------------------\n",
      "‚òÖ EXECUTIVE SUMMARY (AI GENERATED):\n",
      "Beyonce's 2024 Cowboy Carter tour grossed over $400 million, making it the highest-grossing solo tour of the year. The tour featured 32 shows and solidified her financial success. Forbes estimated her total earnings for 2025 at $148 million.\n",
      "----------------------------------------\n",
      "SOURCE [1]: Who run the world? Beyonce's Cowboy Carter is highest grossing ...\n",
      "LINK: https://www.musicradar.com/artists/shows-festivals/who-run-the-world-beyonces-cowboy-carter-is-highest-grossing-solo-tour-of-the-year (Relevance: 0.90)\n",
      "SUMMARY: Beyonce‚Äôs Cowboy Carter tour is apparently the highest-earning solo tour of the year, according to Billboard‚Äôs annual year-end live report.\n",
      "\n",
      "The tour in support of her 2024 album earned $407.6 million, which is all the more impressive considering that figure was from just 32 shows. [...] Whilst Beyonce took the honours when it comes to solo artists, the highest earning tour overall was Coldplay‚Äôs Music Of The Spheres jaunt, which started more than three whole years ago. Chris Martin and co played everywhere in 2025, including ten nights at Wembley and brought in $464.9 million. A distant third behind those two was The Weeknd, whose After Hours Til Dawn tour accumulated $336.7 million.\n",
      "\n",
      "Get the MusicRadar Newsletter [...] This was never better demonstrated than at the California stop on the tour at the SoFi stadium in Inglewood. Beyonce played five nights there in late April and early May, a run that generated a whopping $50 million, or an average of $11.1 million each night. It was the highest single venue engagement of the year and the fifth highest in history, beaten only by U2 at the Sphere in 2023/24, Take That‚Äôs Wembley run in 2011 and Harry Styles at Madison Square Garden in 2022.\n",
      "EXTRACT: Don't miss these # Who run the world? Beyonce‚Äôs Cowboy Carter is highest grossing solo tour of the year [News](https://www.musicradar.com/news) By [Will Simpson](https://www.musicradar.com/author/will-simpson) published ...\n",
      "[Truncated for view]\n",
      "   üß† Curating knowledge from raw content...\n",
      "   üíæ Knowledge Artifact Saved to ./models/pending_knowledge.json\n",
      "------------------------------------------------------------\n",
      "\n",
      "‚úÖ PIPELINE COMPLETE.\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# CELL 4: RUNNING THE PIPELINE\n",
    "# ==========================================\n",
    "# Example atomic questions that might fail RAG\n",
    "missing_tasks = [\n",
    "    \"current net worth Beyonce 2025\",\n",
    "    \"Beyonce recent tour gross earnings 2024\"\n",
    "]\n",
    "\n",
    "print(\"üö® RAG GAP DETECTED. ACTIVATING EXTERNAL CORTEX.\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for task in missing_tasks:\n",
    "    print(f\"\\nüåê TASK: {task}\")\n",
    "    \n",
    "    # 1. Search & Extract\n",
    "    result = scout.search_and_extract(task)\n",
    "    \n",
    "    # 2. Display the 'Agent View' (What the LLM sees)\n",
    "    if result['status'] == 'success':\n",
    "        print(\"\\nüìÑ AGENT CONTEXT BLOCK (Preview):\")\n",
    "        print(\"-\" * 40)\n",
    "        # This includes the Tavily 'Advanced Answer' + Source Snippets\n",
    "        print(result['agent_context'][:2000] + \"...\\n[Truncated for view]\") \n",
    "        \n",
    "        # 3. Curate & Memorize\n",
    "        curator.curate(task, result)\n",
    "    else:\n",
    "        print(\"‚ùå Task Failed.\")\n",
    "    \n",
    "    print(\"-\" * 60)\n",
    "\n",
    "print(\"\\n‚úÖ PIPELINE COMPLETE.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c627e4c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
