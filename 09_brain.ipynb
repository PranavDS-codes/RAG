{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cadedbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# CELL 1: DEEP FLIGHT RECORDER (FULL FIDELITY)\n",
    "# ==========================================\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import uuid\n",
    "import logging\n",
    "import copy\n",
    "from datetime import datetime\n",
    "from typing import TypedDict, List, Dict, Literal, Any\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "# --- IMPORT CONFIG & MODULES ---\n",
    "from config import (\n",
    "    GRAPH_PATH, CHUNKS_PATH, VECTOR_INDEX_PATH, BM25_INDEX_PATH, \n",
    "    QUERY_MODEL, SCOUT_MODEL, AUDIT_MODEL, SYNTHESIZE_MODEL,\n",
    "    GROQ_API_KEY, LOG_FILE_PATH, REPORTS_DIR\n",
    ")\n",
    "from rag_engine import OmniRetriever\n",
    "from web_engine import DeepWebScout, KnowledgeCurator\n",
    "\n",
    "# --- SETUP LOGGING ---\n",
    "for handler in logging.root.handlers[:]:\n",
    "    logging.root.removeHandler(handler)\n",
    "logging.basicConfig(\n",
    "    filename=LOG_FILE_PATH,\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    datefmt='%H:%M:%S'\n",
    ")\n",
    "logger = logging.getLogger(\"BRAIN\")\n",
    "\n",
    "class DeepFlightRecorder:\n",
    "    def __init__(self):\n",
    "        self.current_run_id = None\n",
    "        self.run_data = {}\n",
    "        if not os.path.exists(REPORTS_DIR): os.makedirs(REPORTS_DIR)\n",
    "\n",
    "    def start_run(self, query):\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        self.current_run_id = f\"trace_{timestamp}\"\n",
    "        self.run_data = {\n",
    "            \"meta\": { \"run_id\": self.current_run_id, \"query\": query, \"timestamp\": timestamp },\n",
    "            \"trace_log\": []\n",
    "        }\n",
    "        print(f\"üìº Deep Trace started: {self.current_run_id}\")\n",
    "\n",
    "    def log_event(self, event_type: str, component: str, data: Any, duration_ms: float = 0.0):\n",
    "        \"\"\"\n",
    "        Logs a specific internal event with FULL FIDELITY.\n",
    "        \"\"\"\n",
    "        entry = {\n",
    "            \"type\": event_type,\n",
    "            \"component\": component,\n",
    "            \"duration_ms\": round(duration_ms, 2), # Explicit latency tracking\n",
    "            # We enforce a Deep Copy to capture the exact state at that millisecond\n",
    "            # NO TRUNCATION.\n",
    "            \"data\": copy.deepcopy(data) if isinstance(data, (dict, list)) else str(data)\n",
    "        }\n",
    "        self.run_data[\"trace_log\"].append(entry)\n",
    "\n",
    "    def save_report(self):\n",
    "        filename = f\"{self.current_run_id}_deep_trace.json\"\n",
    "        filepath = os.path.join(REPORTS_DIR, filename)\n",
    "        with open(filepath, \"w\", encoding='utf-8') as f:\n",
    "            json.dump(self.run_data, f, indent=2, ensure_ascii=False)\n",
    "        print(f\"üíæ Deep Trace Report saved to: {filepath}\")\n",
    "        return filepath\n",
    "\n",
    "recorder = DeepFlightRecorder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8face9e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öôÔ∏è  Injecting High-Fidelity Probes...\n",
      "üìÇ Loading Resources...\n",
      "üöÄ Omni-Retriever Ready.\n",
      "üöÄ Probes Active.\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# CELL 2: INSTRUMENTED TOOLS (STOPWATCH EDITION)\n",
    "# ==========================================\n",
    "\n",
    "class TracedOmniRetriever(OmniRetriever):\n",
    "    def retrieve(self, query, top_k_per_task=5, verbose=False):\n",
    "        # 1. OPTIMIZATION TRACE\n",
    "        t_start = time.perf_counter()\n",
    "        omni = self.optimizer.optimize(query)\n",
    "        duration = (time.perf_counter() - t_start) * 1000\n",
    "        \n",
    "        recorder.log_event(\"QUERY_DECOMPOSITION\", \"QueryOptimizer\", omni, duration)\n",
    "        \n",
    "        final_structure = {\"original_query\": query, \"tasks\": []}\n",
    "        \n",
    "        # 2. ATOMIC EXECUTION TRACE\n",
    "        for i, task in enumerate(omni['tasks']):\n",
    "            sub_q = task['sub_query']\n",
    "            candidates = {} \n",
    "            \n",
    "            # --- A. VECTOR SEARCH (Full Text) ---\n",
    "            t0 = time.perf_counter()\n",
    "            vector_hits = []\n",
    "            if task['hyde_passage']:\n",
    "                emb = self.embedder.encode([task['hyde_passage']], convert_to_numpy=True)\n",
    "                D, I = self.index.search(emb, k=top_k_per_task*2)\n",
    "                for idx in I[0]: \n",
    "                    if idx < len(self.chunks): \n",
    "                        txt = self.chunks[idx]['text']\n",
    "                        candidates[txt] = 0.0\n",
    "                        vector_hits.append(txt) # FULL TEXT\n",
    "            \n",
    "            vec_dur = (time.perf_counter() - t0) * 1000\n",
    "            recorder.log_event(\"SEARCH_VECTOR\", f\"Task_{i}\", {\n",
    "                \"hyde_passage\": task['hyde_passage'], # FULL TEXT\n",
    "                \"hit_count\": len(vector_hits), \n",
    "                \"full_results\": vector_hits # FULL TEXT\n",
    "            }, vec_dur)\n",
    "\n",
    "            # --- B. GRAPH SEARCH (Full Text) ---\n",
    "            t0 = time.perf_counter()\n",
    "            graph_hits = []\n",
    "            for entity in task['graph_entities']:\n",
    "                if entity in self.graph_engine.G: \n",
    "                    facts = self.graph_engine.get_neighbors(entity)\n",
    "                    for f in facts: \n",
    "                        candidates[f] = 0.0\n",
    "                        graph_hits.append(f)\n",
    "            \n",
    "            graph_dur = (time.perf_counter() - t0) * 1000\n",
    "            recorder.log_event(\"SEARCH_GRAPH\", f\"Task_{i}\", {\n",
    "                \"entities\": task['graph_entities'], \n",
    "                \"hit_count\": len(graph_hits), \n",
    "                \"full_facts\": graph_hits # FULL TEXT\n",
    "            }, graph_dur)\n",
    "            \n",
    "            # --- C. RERANKING (Full Scores) ---\n",
    "            t0 = time.perf_counter()\n",
    "            unique_docs = list(candidates.keys())\n",
    "            if not unique_docs:\n",
    "                results = []\n",
    "            else:\n",
    "                pairs = [[sub_q, doc] for doc in unique_docs]\n",
    "                scores = self.reranker.predict(pairs)\n",
    "                ranked = sorted(list(zip(unique_docs, scores)), key=lambda x: x[1], reverse=True)\n",
    "                results = ranked[:top_k_per_task]\n",
    "                \n",
    "                # LOG FULL SCORES\n",
    "                score_log = [{\"text\": r[0], \"score\": float(r[1])} for r in results]\n",
    "                \n",
    "            rerank_dur = (time.perf_counter() - t0) * 1000\n",
    "            recorder.log_event(\"RERANKER_SCORES\", f\"Task_{i}\", score_log, rerank_dur)\n",
    "\n",
    "            final_structure[\"tasks\"].append({\"sub_query\": sub_q, \"results\": results})\n",
    "            \n",
    "        return final_structure\n",
    "\n",
    "class TracedWebScout(DeepWebScout):\n",
    "    def search_and_extract(self, sub_query: str):\n",
    "        t0 = time.perf_counter()\n",
    "        result = super().search_and_extract(sub_query)\n",
    "        duration = (time.perf_counter() - t0) * 1000\n",
    "        \n",
    "        # Capture raw Tavily output structure\n",
    "        recorder.log_event(\"WEB_SEARCH_RAW\", \"DeepWebScout\", result, duration)\n",
    "        return result\n",
    "\n",
    "# INITIALIZE\n",
    "print(\"‚öôÔ∏è  Injecting High-Fidelity Probes...\")\n",
    "traced_retriever = TracedOmniRetriever(GRAPH_PATH, CHUNKS_PATH, VECTOR_INDEX_PATH, BM25_INDEX_PATH, QUERY_MODEL)\n",
    "traced_scout = TracedWebScout()\n",
    "print(\"üöÄ Probes Active.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce57f9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# CELL 3: THE AGENT NODES\n",
    "# ==========================================\n",
    "\n",
    "class BrainState(TypedDict):\n",
    "    query: str\n",
    "    internal_knowledge: List[str]\n",
    "    external_knowledge: List[str]\n",
    "    gap_analysis: Dict\n",
    "    final_answer: str\n",
    "\n",
    "def retrieve_node(state: BrainState):\n",
    "    query = state[\"query\"]\n",
    "    print(f\"\\nüìö [LIBRARIAN] Executing Traced Retrieval...\")\n",
    "    \n",
    "    t0 = time.perf_counter()\n",
    "    results = traced_retriever.retrieve(query, top_k_per_task=3)\n",
    "    duration = (time.perf_counter() - t0) * 1000\n",
    "    \n",
    "    evidence = []\n",
    "    for task in results.get(\"tasks\", []):\n",
    "        sub_q = task[\"sub_query\"]\n",
    "        for txt, score in task[\"results\"]:\n",
    "            evidence.append(f\"[Score: {score:.2f}] {txt}\")\n",
    "    \n",
    "    recorder.log_event(\"NODE_OUTPUT\", \"retrieve_node\", {\"evidence_count\": len(evidence)}, duration)\n",
    "    return {\"internal_knowledge\": evidence}\n",
    "\n",
    "def audit_node(state: BrainState):\n",
    "    print(\"üïµÔ∏è‚Äç‚ôÇÔ∏è [AUDITOR] Auditing Evidence & Freshness...\")\n",
    "    t0 = time.perf_counter()\n",
    "    \n",
    "    query = state[\"query\"]\n",
    "    evidence_text = \"\\n\".join(state[\"internal_knowledge\"][:20]) # Increased context limit\n",
    "    \n",
    "    sys_msg = \"\"\"\n",
    "        You are the Gap Analysis & Freshness Auditor.\n",
    "        Your Job: Evaluate if the provided INTERNAL EVIDENCE is sufficient to answer the USER QUERY fully and accurately.\n",
    "\n",
    "        ### CRITICAL \"FRESHNESS\" RULES:\n",
    "        1. **Assume Stale Data:** Internal data is static. If the user asks for \"current,\" \"latest,\" \"2024/2025,\" \"today,\" or \"news,\" and the evidence does not explicitly contain recent timestamps (last 30 days), you MUST mark it as **INSUFFICIENT**.\n",
    "        2. **Dynamic Topics:** For queries about volatile topics (stock prices, weather, software versions, recent events), strictly reject internal data unless it is verified as live/real-time.\n",
    "        3. **Trigger Search:** When rejecting data due to age/freshness, format your `missing_topics` specifically to guide a web search (e.g., use \"Current status of X\" or \"2025 updates for Y\").\n",
    "\n",
    "        ### OUTPUT SCHEMA (Strict JSON):\n",
    "        { \n",
    "            \"sufficient\": boolean, \n",
    "            \"missing_topics\": [\n",
    "                \"Topic 1 (e.g., 'Latest 2025 features for Python')\",\n",
    "                \"Topic 2 (e.g., 'Current stock price of NVDA')\"\n",
    "            ] \n",
    "        }\n",
    "        \"\"\"\n",
    "    user_msg = f\"QUERY: {query}\\n\\nINTERNAL EVIDENCE:\\n{evidence_text}\"\n",
    "    \n",
    "    # Init LLM\n",
    "    audit_llm = ChatGroq(temperature=0, model_name=AUDIT_MODEL, api_key=GROQ_API_KEY)\n",
    "    \n",
    "    response = audit_llm.invoke([\n",
    "        SystemMessage(content=sys_msg),\n",
    "        HumanMessage(content=user_msg)\n",
    "    ])\n",
    "    \n",
    "    duration = (time.perf_counter() - t0) * 1000\n",
    "    \n",
    "    # LOG FULL PROMPT AND RESPONSE\n",
    "    recorder.log_event(\"LLM_AUDIT\", \"AuditNode\", {\n",
    "        \"full_system_prompt\": sys_msg,\n",
    "        \"full_user_prompt\": user_msg,\n",
    "        \"full_response\": response.content\n",
    "    }, duration)\n",
    "    \n",
    "    try:\n",
    "        analysis = json.loads(response.content)\n",
    "    except:\n",
    "        analysis = {\"sufficient\": False, \"missing_topics\": [query]}\n",
    "        \n",
    "    if analysis.get(\"sufficient\"):\n",
    "        print(\"   ‚úÖ Evidence is sufficient & fresh.\")\n",
    "    else:\n",
    "        print(f\"   ‚ùå Gaps/Stale Data detected: {analysis.get('missing_topics')}\")\n",
    "\n",
    "    return {\"gap_analysis\": analysis}\n",
    "\n",
    "def web_search_node(state: BrainState):\n",
    "    gaps = state[\"gap_analysis\"].get(\"missing_topics\", [])\n",
    "    print(f\"üåê [SCOUT] Tracing Web Search for {len(gaps)} gaps...\")\n",
    "    external_facts = []\n",
    "    \n",
    "    t0 = time.perf_counter()\n",
    "    for gap in gaps:\n",
    "        res = traced_scout.search_and_extract(gap)\n",
    "        if res[\"status\"] == \"success\":\n",
    "            external_facts.append(f\"[Web: {gap}] {res.get('tavily_answer', '')}\")\n",
    "    duration = (time.perf_counter() - t0) * 1000\n",
    "            \n",
    "    recorder.log_event(\"NODE_OUTPUT\", \"web_search_node\", {\"facts_found\": len(external_facts)}, duration)\n",
    "    return {\"external_knowledge\": external_facts}\n",
    "\n",
    "def synthesize_node(state: BrainState):\n",
    "    print(\"‚úçÔ∏è [SYNTHESIZER] Writing Final Answer...\")\n",
    "    t0 = time.perf_counter()\n",
    "    \n",
    "    synth_llm = ChatGroq(temperature=0, model_name=SYNTHESIZE_MODEL, api_key=GROQ_API_KEY)\n",
    "    \n",
    "    sys_msg = \"\"\"\n",
    "        You are the **Chief Intelligence Officer**. \n",
    "        Your mandate is to synthesize fragmented information into a cohesive, executive-level intelligence briefing.\n",
    "\n",
    "        ### CORE OBJECTIVES:\n",
    "        1. **Executive Synthesis**: Do not just list facts. Synthesize them into a narrative that directly answers the user's intent. Start with a **Bottom Line Up Front (BLUF)** summary.\n",
    "        2. **Hybrid Citation Protocol**: You must rigorously attribute every claim to its origin to maintain the chain of custody for information.\n",
    "        - **Internal Data**: Cite as `[Internal Database]`.\n",
    "        - **External Web Data**: Cite as `[Source: domain.com]`.\n",
    "        - **Combined**: If a point is supported by both, use `[Internal Database | Source: domain.com]`.\n",
    "\n",
    "        ### CONFLICT RESOLUTION:\n",
    "        - If External and Internal sources conflict, present **both** viewpoints but prioritize the source with the more recent timestamp.\n",
    "        - Explicitly label discrepancies: *\"Note: Internal records indicate X, while recent public reporting suggests Y.\"*\n",
    "\n",
    "        ### OUTPUT STRUCTURE:\n",
    "        ## Executive Summary\n",
    "        (A 2-3 sentence direct answer.)\n",
    "\n",
    "        ## Detailed Analysis\n",
    "        (Structured findings with \n",
    "        ## Strategic Implications / Next Steps\n",
    "        (Actionable insights based on the data.)\n",
    "\n",
    "        ### CONSTRAINT:\n",
    "        - Answer ONLY using the provided context. If the context is missing specific details, state: \"Insufficient intelligence available regarding [Topic].\"\n",
    "        \"\"\"\n",
    "    user_msg = f\"\"\"\n",
    "    QUESTION: {state['query']}\n",
    "    INTERNAL: {state['internal_knowledge']}\n",
    "    EXTERNAL: {state.get('external_knowledge', [])}\n",
    "    \"\"\"\n",
    "    \n",
    "    response = synth_llm.invoke([\n",
    "        SystemMessage(content=sys_msg),\n",
    "        HumanMessage(content=user_msg)\n",
    "    ])\n",
    "    \n",
    "    duration = (time.perf_counter() - t0) * 1000\n",
    "    \n",
    "    recorder.log_event(\"LLM_SYNTHESIS\", \"SynthesizeNode\", {\n",
    "        \"full_system_prompt\": sys_msg,\n",
    "        \"full_user_prompt\": user_msg,\n",
    "        \"full_response\": response.content\n",
    "    }, duration)\n",
    "    \n",
    "    return {\"final_answer\": response.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3ad75d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# CELL 4: EXECUTION\n",
    "# ==========================================\n",
    "\n",
    "workflow = StateGraph(BrainState)\n",
    "workflow.add_node(\"retrieve\", retrieve_node)\n",
    "workflow.add_node(\"audit\", audit_node)\n",
    "workflow.add_node(\"web_search\", web_search_node)\n",
    "workflow.add_node(\"synthesize\", synthesize_node)\n",
    "\n",
    "workflow.set_entry_point(\"retrieve\")\n",
    "workflow.add_edge(\"retrieve\", \"audit\")\n",
    "workflow.add_conditional_edges(\"audit\", \n",
    "    lambda x: \"synthesize\" if x[\"gap_analysis\"].get(\"sufficient\") else \"web_search\",\n",
    "    {\"synthesize\": \"synthesize\", \"web_search\": \"web_search\"}\n",
    ")\n",
    "workflow.add_edge(\"web_search\", \"synthesize\")\n",
    "workflow.add_edge(\"synthesize\", END)\n",
    "app = workflow.compile()\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "def ask_brain_full_fidelity(question: str):\n",
    "    recorder.start_run(question)\n",
    "    \n",
    "    print(f\"\\n‚ùì QUERY: {question}\\n\" + \"=\"*40)\n",
    "    \n",
    "    try:\n",
    "        result = app.invoke({\"query\": question})\n",
    "        display(Markdown(result[\"final_answer\"]))\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "    finally:\n",
    "        path = recorder.save_report()\n",
    "        print(f\"\\nüìÑ FULL FIDELITY LOG: {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3718103d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìº Deep Trace started: trace_20260104_133034\n",
      "\n",
      "‚ùì QUERY: What is Beyonce's net worth and who is her husband?\n",
      "========================================\n",
      "\n",
      "üìö [LIBRARIAN] Executing Traced Retrieval...\n",
      "‚ö†Ô∏è Note: LLM returned flat format. Converting to Atomic Tasks...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c698981b98d438f9355d058a9fd8e21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0962288cc58449209a5eb4313f011634",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64a06202d0194c0c994a04732137b336",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cee35b00aa446ecb5c213d09683265f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üïµÔ∏è‚Äç‚ôÇÔ∏è [AUDITOR] Auditing Evidence & Freshness...\n",
      "   ‚ùå Gaps/Stale Data detected: ['Current net worth of Beyonc√© (as of 2026)']\n",
      "üåê [SCOUT] Tracing Web Search for 1 gaps...\n",
      "   üîé Scouting External Cortex for: 'Current net worth of Beyonc√© (as of 2026)'...\n",
      "   üëÄ Retrieved 5 high-fidelity sources...\n",
      "‚úçÔ∏è [SYNTHESIZER] Writing Final Answer...\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## Executive Summary  \n",
       "- **Bottom Line Up Front (BLUF):** Beyonc√©‚Äôs net worth is reported at **$1.1‚ÄØbillion** in the most recent 2026 public sources, up from the **$780‚ÄØmillion** figure cited by internal records as of June‚ÄØ2025. She is married to **Jay‚ÄØZ** (Shawn Carter).  \n",
       "\n",
       "---\n",
       "\n",
       "## Detailed Analysis  \n",
       "\n",
       "### Net Worth  \n",
       "| Source | Reported Net Worth | Date |\n",
       "|--------|-------------------|------|\n",
       "| Internal Database ‚Äì Forbes estimate | **$780‚ÄØmillion** | June‚ÄØ2025‚ÄØ[Internal Database] |\n",
       "| External Web ‚Äì Current reporting | **$1.1‚ÄØbillion** | 2026‚ÄØ[Source: web] |\n",
       "\n",
       "**Discrepancy Note:** Internal records list Beyonc√©‚Äôs net worth at $780‚ÄØmillion (June‚ÄØ2025), while a recent external web source (2026) states she has reached billionaire status at $1.1‚ÄØbillion. The external figure is more recent and therefore takes precedence for current assessments, though the internal figure remains a valid historical benchmark.\n",
       "\n",
       "### Marital Status  \n",
       "- Beyonc√© is **married to Jay‚ÄØZ (Shawn Carter)**. This relationship is documented in the internal database with a confidence score of 5.37 and corroborated by marriage date entries (April‚ÄØ4,‚ÄØ2008; public revelation October‚ÄØ22,‚ÄØ2008)‚ÄØ[Internal Database].\n",
       "\n",
       "No external source contradicts or updates this information.\n",
       "\n",
       "---\n",
       "\n",
       "## Strategic Implications / Next Steps  \n",
       "\n",
       "1. **Financial Forecasting:**  \n",
       "   - Adjust any valuation models or partnership considerations to reflect a **$1.1‚ÄØbillion** net worth as of 2026.  \n",
       "   - Track upcoming Forbes or Bloomberg releases for confirmation and potential upward/downward revisions.\n",
       "\n",
       "2. **Brand & Partnership Opportunities:**  \n",
       "   - Beyonc√©‚Äôs billionaire status enhances her leverage in brand negotiations, sponsorships, and joint ventures.  \n",
       "   - Joint ventures with Jay‚ÄØZ should be evaluated as a **combined ‚Äúbillion‚Äëdollar couple‚Äù** asset, given their historic joint earnings and market influence.\n",
       "\n",
       "3. **Monitoring:**  \n",
       "   - Set alerts for future **Forbes Celebrity 100** updates and any SEC filings related to Beyonc√©‚Äôs business entities (e.g., Parkwood Entertainment, Ivy Park).  \n",
       "   - Verify the external source‚Äôs credibility (domain, methodology) to ensure the $1.1‚ÄØbillion figure is robust before finalizing high‚Äëstakes decisions."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Deep Trace Report saved to: ./models/run_reports/trace_20260104_133034_deep_trace.json\n",
      "\n",
      "üìÑ FULL FIDELITY LOG: ./models/run_reports/trace_20260104_133034_deep_trace.json\n",
      "CPU times: user 491 ms, sys: 229 ms, total: 720 ms\n",
      "Wall time: 16.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# TEST\n",
    "ask_brain_full_fidelity(\"What is Beyonce's net worth and who is her husband?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb573ffd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
