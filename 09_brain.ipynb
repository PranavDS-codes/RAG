{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cadedbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# CELL 1: DEEP FLIGHT RECORDER (FULL FIDELITY)\n",
    "# ==========================================\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import uuid\n",
    "import logging\n",
    "import copy\n",
    "from datetime import datetime\n",
    "from typing import TypedDict, List, Dict, Literal, Any\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "# --- IMPORT CONFIG & MODULES ---\n",
    "from config import (\n",
    "    GRAPH_PATH, CHUNKS_PATH, VECTOR_INDEX_PATH, BM25_INDEX_PATH, \n",
    "    QUERY_MODEL, SCOUT_MODEL, AUDIT_MODEL, SYNTHESIZE_MODEL,\n",
    "    GROQ_API_KEY, LOG_FILE_PATH, REPORTS_DIR\n",
    ")\n",
    "from rag_engine import OmniRetriever\n",
    "from web_engine import DeepWebScout, KnowledgeCurator\n",
    "\n",
    "# --- SETUP LOGGING ---\n",
    "for handler in logging.root.handlers[:]:\n",
    "    logging.root.removeHandler(handler)\n",
    "logging.basicConfig(\n",
    "    filename=LOG_FILE_PATH,\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    datefmt='%H:%M:%S'\n",
    ")\n",
    "logger = logging.getLogger(\"BRAIN\")\n",
    "\n",
    "class DeepFlightRecorder:\n",
    "    def __init__(self):\n",
    "        self.current_run_id = None\n",
    "        self.run_data = {}\n",
    "        if not os.path.exists(REPORTS_DIR): os.makedirs(REPORTS_DIR)\n",
    "\n",
    "    def start_run(self, query):\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        self.current_run_id = f\"trace_{timestamp}\"\n",
    "        self.run_data = {\n",
    "            \"meta\": { \"run_id\": self.current_run_id, \"query\": query, \"timestamp\": timestamp },\n",
    "            \"trace_log\": []\n",
    "        }\n",
    "        print(f\"üìº Deep Trace started: {self.current_run_id}\")\n",
    "\n",
    "    def log_event(self, event_type: str, component: str, data: Any, duration_ms: float = 0.0):\n",
    "        \"\"\"\n",
    "        Logs a specific internal event with FULL FIDELITY.\n",
    "        \"\"\"\n",
    "        entry = {\n",
    "            \"type\": event_type,\n",
    "            \"component\": component,\n",
    "            \"duration_ms\": round(duration_ms, 2), # Explicit latency tracking\n",
    "            # We enforce a Deep Copy to capture the exact state at that millisecond\n",
    "            # NO TRUNCATION.\n",
    "            \"data\": copy.deepcopy(data) if isinstance(data, (dict, list)) else str(data)\n",
    "        }\n",
    "        self.run_data[\"trace_log\"].append(entry)\n",
    "\n",
    "    def save_report(self):\n",
    "        filename = f\"{self.current_run_id}_deep_trace.json\"\n",
    "        filepath = os.path.join(REPORTS_DIR, filename)\n",
    "        with open(filepath, \"w\", encoding='utf-8') as f:\n",
    "            json.dump(self.run_data, f, indent=2, ensure_ascii=False)\n",
    "        print(f\"üíæ Deep Trace Report saved to: {filepath}\")\n",
    "        return filepath\n",
    "\n",
    "recorder = DeepFlightRecorder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8face9e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öôÔ∏è  Injecting High-Fidelity Probes...\n",
      "üìÇ Loading Resources...\n",
      "üöÄ Omni-Retriever Ready.\n",
      "üöÄ Probes Active.\n"
     ]
    }
   ],
   "source": [
    "# CELL 2: INSTRUMENTED TOOLS (STOPWATCH EDITION)\n",
    "# ==========================================\n",
    "\n",
    "class TracedOmniRetriever(OmniRetriever):\n",
    "    def retrieve(self, query, top_k_per_task=5, verbose=False):\n",
    "        # 1. OPTIMIZATION TRACE\n",
    "        t_start = time.perf_counter()\n",
    "        omni = self.optimizer.optimize(query)\n",
    "        duration = (time.perf_counter() - t_start) * 1000\n",
    "        \n",
    "        # Log the full breakdown so we can see the isolated metadata in the UI\n",
    "        recorder.log_event(\"QUERY_DECOMPOSITION\", \"QueryOptimizer\", omni, duration)\n",
    "        \n",
    "        final_structure = {\"original_query\": query, \"tasks\": []}\n",
    "        \n",
    "        # 2. ATOMIC EXECUTION TRACE\n",
    "        for i, task in enumerate(omni['tasks']):\n",
    "            sub_q = task['sub_query']\n",
    "            candidates = {} \n",
    "            \n",
    "            # --- A. VECTOR SEARCH (HyDE) ---\n",
    "            t0 = time.perf_counter()\n",
    "            vector_hits = []\n",
    "            if task.get('hyde_passage'):\n",
    "                emb = self.embedder.encode([task['hyde_passage']], convert_to_numpy=True)\n",
    "                # Matches the new OmniRetriever logic (k*3)\n",
    "                D, I = self.index.search(emb, k=top_k_per_task*3)\n",
    "                for idx in I[0]: \n",
    "                    if idx < len(self.chunks): \n",
    "                        txt = self.chunks[idx]['text']\n",
    "                        candidates[txt] = 0.0\n",
    "                        vector_hits.append(txt) \n",
    "            \n",
    "            vec_dur = (time.perf_counter() - t0) * 1000\n",
    "            recorder.log_event(\"SEARCH_VECTOR\", f\"Task_{i}\", {\n",
    "                \"hyde_used\": task.get('hyde_passage'), \n",
    "                \"hit_count\": len(vector_hits), \n",
    "                \"full_results\": vector_hits \n",
    "            }, vec_dur)\n",
    "\n",
    "            # --- B. BM25 SEARCH (Keywords) --- \n",
    "            # [NEW] Added this block to capture the keyword search\n",
    "            t0 = time.perf_counter()\n",
    "            keyword_hits = []\n",
    "            if task.get('keywords'):\n",
    "                bm25_query = f\"{sub_q} {' '.join(task['keywords'])}\"\n",
    "                tokenized_query = bm25_query.split()\n",
    "                bm25_docs = self.bm25.get_top_n(tokenized_query, self.chunk_texts, n=top_k_per_task*3)\n",
    "                for txt in bm25_docs:\n",
    "                    candidates[txt] = 0.0\n",
    "                    keyword_hits.append(txt)\n",
    "\n",
    "            bm25_dur = (time.perf_counter() - t0) * 1000\n",
    "            recorder.log_event(\"SEARCH_BM25\", f\"Task_{i}\", {\n",
    "                \"keywords_used\": task.get('keywords'),\n",
    "                \"hit_count\": len(keyword_hits),\n",
    "                \"full_results\": keyword_hits\n",
    "            }, bm25_dur)\n",
    "\n",
    "            # --- C. GRAPH SEARCH (Entities) ---\n",
    "            t0 = time.perf_counter()\n",
    "            graph_hits = []\n",
    "            for entity in task.get('graph_entities', []):\n",
    "                # Exact Match\n",
    "                if entity in self.graph_engine.G: \n",
    "                    facts = self.graph_engine.get_neighbors(entity)\n",
    "                    for f in facts: \n",
    "                        candidates[f] = 0.0\n",
    "                        graph_hits.append(f)\n",
    "                # Fuzzy Match (Quick check)\n",
    "                else:\n",
    "                    for node in self.graph_engine.G.nodes():\n",
    "                        if str(node).lower() == entity.lower():\n",
    "                            facts = self.graph_engine.get_neighbors(node)\n",
    "                            for f in facts:\n",
    "                                candidates[f] = 0.0\n",
    "                                graph_hits.append(f)\n",
    "                            break\n",
    "            \n",
    "            graph_dur = (time.perf_counter() - t0) * 1000\n",
    "            recorder.log_event(\"SEARCH_GRAPH\", f\"Task_{i}\", {\n",
    "                \"entities_used\": task.get('graph_entities'), \n",
    "                \"hit_count\": len(graph_hits), \n",
    "                \"full_facts\": graph_hits \n",
    "            }, graph_dur)\n",
    "            \n",
    "            # --- D. RERANKING (Full Scores) ---\n",
    "            t0 = time.perf_counter()\n",
    "            unique_docs = list(candidates.keys())\n",
    "            score_log = []\n",
    "            results = []\n",
    "\n",
    "            if unique_docs:\n",
    "                pairs = [[sub_q, doc] for doc in unique_docs]\n",
    "                scores = self.reranker.predict(pairs)\n",
    "                ranked = sorted(list(zip(unique_docs, scores)), key=lambda x: x[1], reverse=True)\n",
    "                results = ranked[:top_k_per_task]\n",
    "                \n",
    "                # LOG FULL SCORES for visualization\n",
    "                score_log = [{\"text\": r[0], \"score\": float(r[1])} for r in results]\n",
    "                \n",
    "            rerank_dur = (time.perf_counter() - t0) * 1000\n",
    "            recorder.log_event(\"RERANKER_SCORES\", f\"Task_{i}\", score_log, rerank_dur)\n",
    "\n",
    "            final_structure[\"tasks\"].append({\"sub_query\": sub_q, \"results\": results})\n",
    "\n",
    "        # 3. GLOBAL MERGE (New Step)\n",
    "        # We use the parent class method for consistency\n",
    "        combined_context = self._deduplicate_and_flatten(final_structure[\"tasks\"])\n",
    "        final_structure[\"combined_context\"] = combined_context\n",
    "        \n",
    "        return final_structure\n",
    "\n",
    "class TracedWebScout(DeepWebScout):\n",
    "    def search_and_extract(self, sub_query: str):\n",
    "        t0 = time.perf_counter()\n",
    "        result = super().search_and_extract(sub_query)\n",
    "        duration = (time.perf_counter() - t0) * 1000\n",
    "        \n",
    "        # Capture raw Tavily output structure\n",
    "        recorder.log_event(\"WEB_SEARCH_RAW\", \"DeepWebScout\", result, duration)\n",
    "        return result\n",
    "\n",
    "# INITIALIZE\n",
    "print(\"‚öôÔ∏è  Injecting High-Fidelity Probes...\")\n",
    "traced_retriever = TracedOmniRetriever(GRAPH_PATH, CHUNKS_PATH, VECTOR_INDEX_PATH, BM25_INDEX_PATH, QUERY_MODEL)\n",
    "traced_scout = TracedWebScout()\n",
    "print(\"üöÄ Probes Active.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce57f9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# CELL 3: THE AGENT NODES\n",
    "# ==========================================\n",
    "\n",
    "class BrainState(TypedDict):\n",
    "    query: str\n",
    "    internal_knowledge: List[str]\n",
    "    external_knowledge: List[str]\n",
    "    gap_analysis: Dict\n",
    "    final_answer: str\n",
    "\n",
    "def retrieve_node(state: BrainState):\n",
    "    query = state[\"query\"]\n",
    "    print(f\"\\nüìö [LIBRARIAN] Executing Traced Retrieval...\")\n",
    "    \n",
    "    t0 = time.perf_counter()\n",
    "    results = traced_retriever.retrieve(query, top_k_per_task=3)\n",
    "    duration = (time.perf_counter() - t0) * 1000\n",
    "    \n",
    "    evidence = []\n",
    "    for task in results.get(\"tasks\", []):\n",
    "        sub_q = task[\"sub_query\"]\n",
    "        for txt, score in task[\"results\"]:\n",
    "            evidence.append(f\"[Score: {score:.2f}] {txt}\")\n",
    "    \n",
    "    recorder.log_event(\"NODE_OUTPUT\", \"retrieve_node\", {\"evidence_count\": len(evidence)}, duration)\n",
    "    return {\"internal_knowledge\": evidence}\n",
    "\n",
    "def audit_node(state: BrainState):\n",
    "    print(\"üïµÔ∏è‚Äç‚ôÇÔ∏è [AUDITOR] Auditing Evidence & Freshness...\")\n",
    "    t0 = time.perf_counter()\n",
    "    \n",
    "    query = state[\"query\"]\n",
    "    evidence_text = \"\\n\".join(state[\"internal_knowledge\"][:20]) # Increased context limit\n",
    "    \n",
    "    sys_msg = \"\"\"\n",
    "        You are the Gap Analysis & Freshness Auditor.\n",
    "        Your Job: Evaluate if the provided INTERNAL EVIDENCE is sufficient to answer the USER QUERY fully and accurately.\n",
    "\n",
    "        ### CRITICAL \"FRESHNESS\" RULES:\n",
    "        1. **Assume Stale Data:** Internal data is static. If the user asks for \"current,\" \"latest,\" \"2024/2025,\" \"today,\" or \"news,\" and the evidence does not explicitly contain recent timestamps (last 30 days), you MUST mark it as **INSUFFICIENT**.\n",
    "        2. **Dynamic Topics:** For queries about volatile topics (stock prices, weather, software versions, recent events), strictly reject internal data unless it is verified as live/real-time.\n",
    "        3. **Trigger Search:** When rejecting data due to age/freshness, format your `missing_topics` specifically to guide a web search (e.g., use \"Current status of X\" or \"2025 updates for Y\").\n",
    "\n",
    "        ### OUTPUT SCHEMA (Strict JSON):\n",
    "        { \n",
    "            \"sufficient\": boolean, \n",
    "            \"missing_topics\": [\n",
    "                \"Topic 1 (e.g., 'Latest 2025 features for Python')\",\n",
    "                \"Topic 2 (e.g., 'Current stock price of NVDA')\"\n",
    "            ] \n",
    "        }\n",
    "        \"\"\"\n",
    "    user_msg = f\"QUERY: {query}\\n\\nINTERNAL EVIDENCE:\\n{evidence_text}\"\n",
    "    \n",
    "    # Init LLM\n",
    "    audit_llm = ChatGroq(temperature=0, model_name=AUDIT_MODEL, api_key=GROQ_API_KEY)\n",
    "    \n",
    "    response = audit_llm.invoke([\n",
    "        SystemMessage(content=sys_msg),\n",
    "        HumanMessage(content=user_msg)\n",
    "    ])\n",
    "    \n",
    "    duration = (time.perf_counter() - t0) * 1000\n",
    "    \n",
    "    # LOG FULL PROMPT AND RESPONSE\n",
    "    recorder.log_event(\"LLM_AUDIT\", \"AuditNode\", {\n",
    "        \"full_system_prompt\": sys_msg,\n",
    "        \"full_user_prompt\": user_msg,\n",
    "        \"full_response\": response.content\n",
    "    }, duration)\n",
    "    \n",
    "    try:\n",
    "        analysis = json.loads(response.content)\n",
    "    except:\n",
    "        analysis = {\"sufficient\": False, \"missing_topics\": [query]}\n",
    "        \n",
    "    if analysis.get(\"sufficient\"):\n",
    "        print(\"   ‚úÖ Evidence is sufficient & fresh.\")\n",
    "    else:\n",
    "        print(f\"   ‚ùå Gaps/Stale Data detected: {analysis.get('missing_topics')}\")\n",
    "\n",
    "    return {\"gap_analysis\": analysis}\n",
    "\n",
    "def web_search_node(state: BrainState):\n",
    "    gaps = state[\"gap_analysis\"].get(\"missing_topics\", [])\n",
    "    print(f\"üåê [SCOUT] Tracing Web Search for {len(gaps)} gaps...\")\n",
    "    external_facts = []\n",
    "    \n",
    "    t0 = time.perf_counter()\n",
    "    for gap in gaps:\n",
    "        res = traced_scout.search_and_extract(gap)\n",
    "        if res[\"status\"] == \"success\":\n",
    "            external_facts.append(f\"[Web: {gap}] {res.get('tavily_answer', '')}\")\n",
    "    duration = (time.perf_counter() - t0) * 1000\n",
    "            \n",
    "    recorder.log_event(\"NODE_OUTPUT\", \"web_search_node\", {\"facts_found\": len(external_facts)}, duration)\n",
    "    return {\"external_knowledge\": external_facts}\n",
    "\n",
    "def synthesize_node(state: BrainState):\n",
    "    print(\"‚úçÔ∏è [SYNTHESIZER] Writing Final Answer...\")\n",
    "    t0 = time.perf_counter()\n",
    "    \n",
    "    synth_llm = ChatGroq(temperature=0, model_name=SYNTHESIZE_MODEL, api_key=GROQ_API_KEY)\n",
    "    \n",
    "    sys_msg = \"\"\"\n",
    "        You are the **Chief Intelligence Officer**. \n",
    "        Your mandate is to synthesize fragmented information into a cohesive, executive-level intelligence briefing.\n",
    "\n",
    "        ### CORE OBJECTIVES:\n",
    "        1. **Executive Synthesis**: Do not just list facts. Synthesize them into a narrative that directly answers the user's intent. Start with a **Bottom Line Up Front (BLUF)** summary.\n",
    "        2. **Hybrid Citation Protocol**: You must rigorously attribute every claim to its origin to maintain the chain of custody for information.\n",
    "        - **Internal Data**: Cite as `[Internal Database]`.\n",
    "        - **External Web Data**: Cite as `[Source: domain.com]`.\n",
    "        - **Combined**: If a point is supported by both, use `[Internal Database | Source: domain.com]`.\n",
    "\n",
    "        ### CONFLICT RESOLUTION:\n",
    "        - If External and Internal sources conflict, present **both** viewpoints but prioritize the source with the more recent timestamp.\n",
    "        - Explicitly label discrepancies: *\"Note: Internal records indicate X, while recent public reporting suggests Y.\"*\n",
    "\n",
    "        ### OUTPUT STRUCTURE:\n",
    "        ## Executive Summary\n",
    "        (A 2-3 sentence direct answer.)\n",
    "\n",
    "        ## Detailed Analysis\n",
    "        (Structured findings with \n",
    "        ## Strategic Implications / Next Steps\n",
    "        (Actionable insights based on the data.)\n",
    "\n",
    "        ### CONSTRAINT:\n",
    "        - Answer ONLY using the provided context. If the context is missing specific details, state: \"Insufficient intelligence available regarding [Topic].\"\n",
    "        \"\"\"\n",
    "    user_msg = f\"\"\"\n",
    "    QUESTION: {state['query']}\n",
    "    INTERNAL: {state['internal_knowledge']}\n",
    "    EXTERNAL: {state.get('external_knowledge', [])}\n",
    "    \"\"\"\n",
    "    \n",
    "    response = synth_llm.invoke([\n",
    "        SystemMessage(content=sys_msg),\n",
    "        HumanMessage(content=user_msg)\n",
    "    ])\n",
    "    \n",
    "    duration = (time.perf_counter() - t0) * 1000\n",
    "    \n",
    "    recorder.log_event(\"LLM_SYNTHESIS\", \"SynthesizeNode\", {\n",
    "        \"full_system_prompt\": sys_msg,\n",
    "        \"full_user_prompt\": user_msg,\n",
    "        \"full_response\": response.content\n",
    "    }, duration)\n",
    "    \n",
    "    return {\"final_answer\": response.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3ad75d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# CELL 4: EXECUTION\n",
    "# ==========================================\n",
    "\n",
    "workflow = StateGraph(BrainState)\n",
    "workflow.add_node(\"retrieve\", retrieve_node)\n",
    "workflow.add_node(\"audit\", audit_node)\n",
    "workflow.add_node(\"web_search\", web_search_node)\n",
    "workflow.add_node(\"synthesize\", synthesize_node)\n",
    "\n",
    "workflow.set_entry_point(\"retrieve\")\n",
    "workflow.add_edge(\"retrieve\", \"audit\")\n",
    "workflow.add_conditional_edges(\"audit\", \n",
    "    lambda x: \"synthesize\" if x[\"gap_analysis\"].get(\"sufficient\") else \"web_search\",\n",
    "    {\"synthesize\": \"synthesize\", \"web_search\": \"web_search\"}\n",
    ")\n",
    "workflow.add_edge(\"web_search\", \"synthesize\")\n",
    "workflow.add_edge(\"synthesize\", END)\n",
    "app = workflow.compile()\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "def ask_brain_full_fidelity(question: str):\n",
    "    recorder.start_run(question)\n",
    "    \n",
    "    print(f\"\\n‚ùì QUERY: {question}\\n\" + \"=\"*40)\n",
    "    \n",
    "    try:\n",
    "        result = app.invoke({\"query\": question})\n",
    "        display(Markdown(result[\"final_answer\"]))\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "    finally:\n",
    "        path = recorder.save_report()\n",
    "        print(f\"\\nüìÑ FULL FIDELITY LOG: {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3718103d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìº Deep Trace started: trace_20260118_113418\n",
      "\n",
      "‚ùì QUERY: Why are newborns described as being physiologically immunodeficient?\n",
      "========================================\n",
      "\n",
      "üìö [LIBRARIAN] Executing Traced Retrieval...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dc5c327afad4b67840b7f8da881625c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42ebe4eff0fd4ea2aca7d5cadb39a51c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6efc14f8af6a470fb7581d1bc5310bff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad2e62b66fce4f61a3f045ccdcc27ba4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e71b7fadeb6498da85ae39bf31b76eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "218b1636b6054ce38c0c007bd1a9edb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üïµÔ∏è‚Äç‚ôÇÔ∏è [AUDITOR] Auditing Evidence & Freshness...\n",
      "   ‚úÖ Evidence is sufficient & fresh.\n",
      "‚úçÔ∏è [SYNTHESIZER] Writing Final Answer...\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## Executive Summary  \n",
       "Newborns are termed **physiologically immunodeficient** because at birth they rely almost entirely on maternally‚Äëderived antibodies and possess an immature innate and adaptive immune system that lacks sufficient cell‚Äëmediated responses, complement activity, and high‚Äëaffinity antibody production. This transient deficiency makes them especially vulnerable to infection until their own immune components mature over the first year of life.‚ÄØ[Internal Database]\n",
       "\n",
       "## Detailed Analysis  \n",
       "\n",
       "| Aspect | Why it contributes to physiological immunodeficiency | Evidence |\n",
       "|--------|------------------------------------------------------|----------|\n",
       "| **Absence of self‚Äëproduced immunoglobulins** | IgM, IgD, IgE and IgA do not cross the placenta, so newborns have virtually no endogenous antibodies at birth; they depend on maternal IgG transferred via the FcRn receptor. | ‚ÄúAt birth, most of the immunoglobulin present is maternal IgG‚Ä¶ IgM, IgD, IgE and IgA do not cross the placenta, they are almost undetectable at birth.‚Äù‚ÄØ[Internal Database] |\n",
       "| **Limited duration and low affinity of passive antibodies** | Maternal IgG provides short‚Äëterm protection (up to ~18‚ÄØmonths) but is of low affinity and wanes quickly; breast‚Äëmilk IgA offers only mucosal protection for a few months. | ‚ÄúThese passively‚Äëacquired antibodies can protect the newborn for up to 18 months, but their response is usually short‚Äëlived and of low affinity.‚Äù‚ÄØ[Internal Database] |\n",
       "| **Immature T‚Äëcell responses** | Neonatal T‚Äëcells respond poorly to Th1‚Äëtype vaccines; the Th1/Th2 balance is skewed, limiting cell‚Äëmediated immunity against intracellular pathogens. | ‚ÄúVaccines that induce Th1 responses in adults do not readily elicit these same responses in neonates.‚Äù‚ÄØ[Internal Database] |\n",
       "| **Underdeveloped innate functions** | Newborns have reduced complement activity, phagocyte function, and cytokine production, all of which are essential for early pathogen clearance. | ‚ÄúDiets lacking sufficient protein are associated with impaired cell‚Äëmediated immunity, complement activity, phagocyte function, IgA antibody concentrations, and cytokine production.‚Äù‚ÄØ[Internal Database] |\n",
       "| **Thymic immaturity** | The thymus is relatively small and its output of na√Øve T cells is limited; any early loss (genetic or surgical) leads to severe immunodeficiency. | ‚ÄúThe loss of the thymus at an early age‚Ä¶ results in severe immunodeficiency and a high susceptibility to infection.‚Äù‚ÄØ[Internal Database] |\n",
       "| **No prior microbial exposure** | Without previous antigen encounters, newborns lack memory B and T cells, reducing the speed and specificity of adaptive responses. | ‚ÄúNewborn infants have no prior exposure to microbes and are particularly vulnerable to infection.‚Äù‚ÄØ[Internal Database] |\n",
       "| **Maternal antibody interference** | Existing maternal IgG can suppress the infant‚Äôs own antibody response to vaccination (immune tolerance), further delaying active immunity. | ‚ÄúPassively acquired maternal antibodies can suppress the antibody response to active immunization.‚Äù‚ÄØ[Internal Database] |\n",
       "\n",
       "Collectively, these factors create a **physiological state of immunodeficiency** that is normal for the neonatal period but resolves as the infant‚Äôs immune system matures (generally by 6‚Äì12‚ÄØmonths for protein antigens and later for polysaccharide antigens).‚ÄØ[Internal Database]\n",
       "\n",
       "## Strategic Implications / Next Steps  \n",
       "\n",
       "1. **Vaccination Scheduling** ‚Äì Align immunization programs with the known maturation windows (e.g., prioritize protein‚Äëbased vaccines early, defer polysaccharide vaccines until ‚â•12‚ÄØmonths).  \n",
       "2. **Passive Immunity Augmentation** ‚Äì Consider prophylactic administration of immunoglobulin preparations or monoclonal antibodies for high‚Äërisk neonates (e.g., preterm, immunocompromised).  \n",
       "3. **Maternal Immunization** ‚Äì Boost maternal IgG levels through vaccination during pregnancy to enhance passive protection for the newborn.  \n",
       "4. **Monitoring & Early Intervention** ‚Äì Implement heightened surveillance for infections in the first months of life, especially in settings with malnutrition or thymic compromise.  \n",
       "5. **Research Priorities** ‚Äì Investigate adjuvants or vaccine platforms that can safely elicit robust Th1 responses in neonates, overcoming the intrinsic T‚Äëcell bias.  \n",
       "\n",
       "These actions leverage the understanding that newborn immunodeficiency is a predictable, time‚Äëlimited condition, allowing targeted interventions to bridge the gap until the infant‚Äôs own immune competence is established.‚ÄØ[Internal Database]"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Deep Trace Report saved to: ./models/run_reports/trace_20260118_113418_deep_trace.json\n",
      "\n",
      "üìÑ FULL FIDELITY LOG: ./models/run_reports/trace_20260118_113418_deep_trace.json\n",
      "CPU times: user 688 ms, sys: 87.5 ms, total: 775 ms\n",
      "Wall time: 6.16 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# TEST\n",
    "ask_brain_full_fidelity(\"Why are newborns described as being physiologically immunodeficient?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb573ffd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
