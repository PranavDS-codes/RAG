{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "725766d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Groq Client Configured with model: llama-3.3-70b-versatile\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# CELL 1: SETUP & KEY MANAGEMENT\n",
    "# ==========================================\n",
    "# !pip install groq faiss-cpu sentence-transformers\n",
    "\n",
    "import os\n",
    "import getpass\n",
    "from groq import Groq\n",
    "import json\n",
    "import gc\n",
    "import pickle\n",
    "import numpy as np\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from dotenv import load_dotenv\n",
    "from rag_evaluation import RAGEvaluator\n",
    "import pandas as pd\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# 1. Securely Input API Key\n",
    "# If you haven't set it in your environment, this will prompt you.\n",
    "if \"GROQ_API_KEY\" not in os.environ:\n",
    "    print(\"üîë Enter your Groq API Key (Input will be hidden):\")\n",
    "    os.environ[\"GROQ_API_KEY\"] = getpass.getpass()\n",
    "# 2. Initialize Groq Client\n",
    "client = Groq(\n",
    "    api_key=os.environ.get(\"GROQ_API_KEY\"),\n",
    ")\n",
    "# print(os.environ[\"GROQ_API_KEY\"])\n",
    "\n",
    "# 3. Define Model\n",
    "# Llama 3.3 70B is the current SOTA on Groq for reasoning\n",
    "LLM_MODEL = \"llama-3.3-70b-versatile\"\n",
    "# LLM_MODEL = \"openai/gpt-oss-120b\"\n",
    "\n",
    "print(f\"‚úÖ Groq Client Configured with model: {LLM_MODEL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "589d3e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öôÔ∏è Loading Retrieval Engine...\n",
      "‚úÖ System Ready. Index contains 39141 documents.\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# CELL 2: THE RETRIEVER CLASS (The \"Memory\")\n",
    "# ==========================================\n",
    "class Retriever:\n",
    "    def __init__(self, model_path=\"./models\"):\n",
    "        print(\"‚öôÔ∏è Loading Retrieval Engine...\")\n",
    "        \n",
    "        # 1. Load Embedding Model (Must match Phase 2!)\n",
    "        # We use the same BAAI/bge-small model to ensure vectors match\n",
    "        self.encoder = SentenceTransformer(\"BAAI/bge-small-en-v1.5\")\n",
    "        \n",
    "        # 2. Load FAISS Index\n",
    "        self.index = faiss.read_index(f\"{model_path}/faiss_index.bin\")\n",
    "        \n",
    "        # 3. Load Metadata (The actual text)\n",
    "        with open(f\"{model_path}/chunk_metadata.pkl\", \"rb\") as f:\n",
    "            self.chunks = pickle.load(f)\n",
    "            \n",
    "        print(f\"‚úÖ System Ready. Index contains {self.index.ntotal} documents.\")\n",
    "\n",
    "    def search(self, query, k=5):\n",
    "        \"\"\"\n",
    "        Takes a user query, finds the top K most relevant chunks.\n",
    "        \"\"\"\n",
    "        # A. Embed Query\n",
    "        # Remember: bge-models need the instruction for queries\n",
    "        query_prompt = f\"Represent this sentence for searching relevant passages: {query}\"\n",
    "        query_vec = self.encoder.encode(\n",
    "            [query_prompt], \n",
    "            normalize_embeddings=True, \n",
    "            convert_to_numpy=True\n",
    "        )\n",
    "        \n",
    "        # B. Search Index\n",
    "        # D = Distances (Scores), I = Indices (IDs)\n",
    "        D, I = self.index.search(query_vec, k)\n",
    "        \n",
    "        # C. Retrieve Content\n",
    "        results = []\n",
    "        for i in range(k):\n",
    "            idx = I[0][i]\n",
    "            score = D[0][i]\n",
    "            \n",
    "            # Map ID back to text\n",
    "            chunk_data = self.chunks[idx]\n",
    "            \n",
    "            # Append clean result\n",
    "            results.append({\n",
    "                \"text\": chunk_data['text'],\n",
    "                \"title\": chunk_data['title'],\n",
    "                \"score\": float(score),\n",
    "                \"url\": chunk_data['source_url']\n",
    "            })\n",
    "            \n",
    "        return results\n",
    "\n",
    "# Initialize the Retriever once\n",
    "retriever = Retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da8cc35a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ RAG Function Defined.\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# CELL 3: THE GENERATOR (The \"Brain\")\n",
    "# ==========================================\n",
    "def generate_rag_answer(query, retriever_instance, llm_model=\"llama-3.3-70b-versatile\"):\n",
    "    \"\"\"\n",
    "    The Full RAG Pipeline: Retrieve -> Augment -> Generate\n",
    "    \"\"\"\n",
    "    # 1. RETRIEVE\n",
    "    # We fetch top 3 chunks. 3 is usually the sweet spot for context window vs focus.\n",
    "    retrieved_docs = retriever_instance.search(query, k=3)\n",
    "    \n",
    "    # 2. AUGMENT (Context Construction)\n",
    "    # We join the chunks into a single string for the LLM\n",
    "    context_text = \"\"\n",
    "    for i, doc in enumerate(retrieved_docs):\n",
    "        context_text += f\"Source {i+1} ({doc['title']}):\\n{doc['text']}\\n\\n\"\n",
    "    \n",
    "    # 3. PROMPT ENGINEERING\n",
    "    # We force the model to be a \"Strict Scholar\" - only using provided context.\n",
    "    system_prompt = \"\"\"You are a helpful, accurate AI assistant. \n",
    "    You have access to a specific Knowledge Base. \n",
    "    ALWAYS answer the user's question using ONLY the context provided below.\n",
    "    If the answer is not in the context, strictly state: \"I cannot answer this based on the provided documents.\"\n",
    "    Do not hallucinate or use outside knowledge.\n",
    "    \"\"\"\n",
    "    \n",
    "    user_prompt = f\"\"\"\n",
    "    Context Information:\n",
    "    ---------------------\n",
    "    {context_text}\n",
    "    ---------------------\n",
    "    \n",
    "    User Question: {query}\n",
    "    \n",
    "    Answer:\n",
    "    \"\"\"\n",
    "    \n",
    "    # 4. GENERATE (Groq API)\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ],\n",
    "        model=llm_model,\n",
    "        temperature=0.1, # Low temp = more factual/deterministic\n",
    "        max_tokens=512,  # Keep answers concise\n",
    "    )\n",
    "    \n",
    "    response_text = chat_completion.choices[0].message.content\n",
    "    \n",
    "    return response_text, retrieved_docs\n",
    "\n",
    "print(\"‚úÖ RAG Function Defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5d5c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# CELL 4: INTERACTIVE TEST\n",
    "# ==========================================\n",
    "# Try asking about something specific in your dataset\n",
    "query = \"When did Beyonce start becoming popular?\"\n",
    "# Or: \"Who managed Destiny's Child?\" (If Beyonce is in your dataset)\n",
    "\n",
    "print(f\"‚ùì Question: {query}\\n\")\n",
    "\n",
    "answer, sources = generate_rag_answer(query, retriever)\n",
    "\n",
    "print(\"ü§ñ AI Answer:\")\n",
    "print(\"-\" * 60)\n",
    "print(answer)\n",
    "print(\"-\" * 60)\n",
    "\n",
    "print(\"\\nüìÑ Sources Used:\")\n",
    "for source in sources:\n",
    "    print(f\"   ‚Ä¢ {source['title']} (Score: {source['score']:.4f}): {source['text']}\")\n",
    "    # print(f\"     Preview: {source['text'][:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67286a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# CELL 2: CONNECT YOUR COMPONENTS\n",
    "# ==========================================\n",
    "# Assuming 'retriever' and 'generate_rag_answer' are defined in previous cells\n",
    "\n",
    "# Initialize the Evaluator\n",
    "evaluator = RAGEvaluator(\n",
    "    retriever_instance=retriever,\n",
    "    generator_func=generate_rag_answer,  # The function from Notebook 03\n",
    "    groq_client=client\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297a2379",
   "metadata": {},
   "source": [
    "## WITHOUT IMPOSSIBLE Questions\n",
    "only 50 samples can be used as its the api limit\n",
    "and it contains the judge eval also"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "710a5212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìö Loaded 92749 validation questions.\n",
      "‚è±Ô∏è Target RPM: 15 | Sleep Base: 4.80s\n",
      "Model: llama-3.3-70b-versatile, Judge: openai/gpt-oss-120b\n",
      "üé≤ Sampling 50 questions...\n",
      "üöÄ Experiment: not_impossible | Judge: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [04:47<00:00,  5.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä EXPERIMENT SUMMARY\n",
      "========================================\n",
      "Total                    : 50.0000\n",
      "Avg F1                   : 0.2880\n",
      "Avg Exact Match          : 0.1000\n",
      "Avg Hit Rate             : 0.9000\n",
      "Avg Faithfulness         : 0.0000\n",
      "Avg Relevance            : 0.0000\n",
      "Avg Context Utility      : 0.0000\n",
      "Avg Coherence            : 0.0000\n",
      "Avg Semantic Similarity  : 0.0000\n",
      "Total API Calls          : 50.0000\n",
      "========================================\n",
      "üíæ Saved: ./data/results/eval_not_impossible_naive_rag_20251221_105432.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>rag_type</th>\n",
       "      <th>model_name</th>\n",
       "      <th>judge_model</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>question</th>\n",
       "      <th>is_impossible</th>\n",
       "      <th>generated_answer</th>\n",
       "      <th>gold_answers</th>\n",
       "      <th>...</th>\n",
       "      <th>exact_match</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>judge_faithfulness</th>\n",
       "      <th>judge_relevance</th>\n",
       "      <th>judge_utility</th>\n",
       "      <th>judge_coherence</th>\n",
       "      <th>judge_similarity</th>\n",
       "      <th>judge_neg_rejection</th>\n",
       "      <th>judge_reasoning</th>\n",
       "      <th>retrieved_context_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>not_impossible_20251221_105432</td>\n",
       "      <td>not_impossible</td>\n",
       "      <td>naive_rag</td>\n",
       "      <td>llama-3.3-70b-versatile</td>\n",
       "      <td>openai/gpt-oss-120b</td>\n",
       "      <td>20251221_105432</td>\n",
       "      <td>What was the name of the scientist who develop...</td>\n",
       "      <td>False</td>\n",
       "      <td>The scientist who developed and published a mo...</td>\n",
       "      <td>['Jean-Baptiste Lamarck']</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2105</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>Charles Darwin's grandfather Erasmus Darwin ou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>not_impossible_20251221_105432</td>\n",
       "      <td>not_impossible</td>\n",
       "      <td>naive_rag</td>\n",
       "      <td>llama-3.3-70b-versatile</td>\n",
       "      <td>openai/gpt-oss-120b</td>\n",
       "      <td>20251221_105432</td>\n",
       "      <td>What is the name of the capital city of Myanmar?</td>\n",
       "      <td>False</td>\n",
       "      <td>The capital city of Myanmar is Naypyidaw.</td>\n",
       "      <td>['capital city is Naypyidaw']</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>Myanmar, officially the Republic of the Union ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>not_impossible_20251221_105432</td>\n",
       "      <td>not_impossible</td>\n",
       "      <td>naive_rag</td>\n",
       "      <td>llama-3.3-70b-versatile</td>\n",
       "      <td>openai/gpt-oss-120b</td>\n",
       "      <td>20251221_105432</td>\n",
       "      <td>What did Tito offer to the retreating column?</td>\n",
       "      <td>False</td>\n",
       "      <td>Tito offered amnesty to the retreating column.</td>\n",
       "      <td>['amnesty']</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>Tito's estrangement from the USSR enabled Yugo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>not_impossible_20251221_105432</td>\n",
       "      <td>not_impossible</td>\n",
       "      <td>naive_rag</td>\n",
       "      <td>llama-3.3-70b-versatile</td>\n",
       "      <td>openai/gpt-oss-120b</td>\n",
       "      <td>20251221_105432</td>\n",
       "      <td>What did these attacks accomplish?</td>\n",
       "      <td>False</td>\n",
       "      <td>I cannot answer this based on the provided doc...</td>\n",
       "      <td>['breaks in morale']</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>Additionally, recent attacker motivations can ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>not_impossible_20251221_105432</td>\n",
       "      <td>not_impossible</td>\n",
       "      <td>naive_rag</td>\n",
       "      <td>llama-3.3-70b-versatile</td>\n",
       "      <td>openai/gpt-oss-120b</td>\n",
       "      <td>20251221_105432</td>\n",
       "      <td>Who does the Chief of Staff serve as the princ...</td>\n",
       "      <td>False</td>\n",
       "      <td>The Chief of Staff of the Army serves as the p...</td>\n",
       "      <td>['Secretary of the Army']</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>The army is led by a civilian Secretary of the...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           run_id experiment_name   rag_type  \\\n",
       "0  not_impossible_20251221_105432  not_impossible  naive_rag   \n",
       "1  not_impossible_20251221_105432  not_impossible  naive_rag   \n",
       "2  not_impossible_20251221_105432  not_impossible  naive_rag   \n",
       "3  not_impossible_20251221_105432  not_impossible  naive_rag   \n",
       "4  not_impossible_20251221_105432  not_impossible  naive_rag   \n",
       "\n",
       "                model_name          judge_model        timestamp  \\\n",
       "0  llama-3.3-70b-versatile  openai/gpt-oss-120b  20251221_105432   \n",
       "1  llama-3.3-70b-versatile  openai/gpt-oss-120b  20251221_105432   \n",
       "2  llama-3.3-70b-versatile  openai/gpt-oss-120b  20251221_105432   \n",
       "3  llama-3.3-70b-versatile  openai/gpt-oss-120b  20251221_105432   \n",
       "4  llama-3.3-70b-versatile  openai/gpt-oss-120b  20251221_105432   \n",
       "\n",
       "                                            question  is_impossible  \\\n",
       "0  What was the name of the scientist who develop...          False   \n",
       "1   What is the name of the capital city of Myanmar?          False   \n",
       "2      What did Tito offer to the retreating column?          False   \n",
       "3                 What did these attacks accomplish?          False   \n",
       "4  Who does the Chief of Staff serve as the princ...          False   \n",
       "\n",
       "                                    generated_answer  \\\n",
       "0  The scientist who developed and published a mo...   \n",
       "1          The capital city of Myanmar is Naypyidaw.   \n",
       "2     Tito offered amnesty to the retreating column.   \n",
       "3  I cannot answer this based on the provided doc...   \n",
       "4  The Chief of Staff of the Army serves as the p...   \n",
       "\n",
       "                    gold_answers  ... exact_match f1_score  \\\n",
       "0      ['Jean-Baptiste Lamarck']  ...           0   0.2105   \n",
       "1  ['capital city is Naypyidaw']  ...           0   0.8000   \n",
       "2                    ['amnesty']  ...           0   0.2857   \n",
       "3           ['breaks in morale']  ...           0   0.0000   \n",
       "4      ['Secretary of the Army']  ...           0   0.3000   \n",
       "\n",
       "   judge_faithfulness  judge_relevance  judge_utility  judge_coherence  \\\n",
       "0                 0.0              0.0            0.0              0.0   \n",
       "1                 0.0              0.0            0.0              0.0   \n",
       "2                 0.0              0.0            0.0              0.0   \n",
       "3                 0.0              0.0            0.0              0.0   \n",
       "4                 0.0              0.0            0.0              0.0   \n",
       "\n",
       "   judge_similarity  judge_neg_rejection  judge_reasoning  \\\n",
       "0               0.0                  NaN                    \n",
       "1               0.0                  NaN                    \n",
       "2               0.0                  NaN                    \n",
       "3               0.0                  NaN                    \n",
       "4               0.0                  NaN                    \n",
       "\n",
       "                              retrieved_context_text  \n",
       "0  Charles Darwin's grandfather Erasmus Darwin ou...  \n",
       "1  Myanmar, officially the Republic of the Union ...  \n",
       "2  Tito's estrangement from the USSR enabled Yugo...  \n",
       "3  Additionally, recent attacker motivations can ...  \n",
       "4  The army is led by a civilian Secretary of the...  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### WITHOUT IMPOSSIBLE\n",
    "with open(\"./data/raw/squad_eval_set_all.json\", \"r\") as f:\n",
    "    raw_data = json.load(f)\n",
    "    \n",
    "# Filter only validation data\n",
    "# eval_dataset = raw_data\n",
    "eval_dataset = [x for x in raw_data if x['is_impossible'] == False]\n",
    "# eval_dataset = [x for x in raw_data if x['split'] == 'validation']\n",
    "print(f\"üìö Loaded {len(eval_dataset)} validation questions.\")\n",
    "\n",
    "del raw_data\n",
    "gc.collect()\n",
    "\n",
    "# ==========================================\n",
    "# CELL 3: RUN EXPERIMENT 1 (Baseline)\n",
    "# ==========================================\n",
    "\n",
    "# Let's run a test with 30 questions\n",
    "df, summary = evaluator.run_experiment(\n",
    "    dataset=eval_dataset,\n",
    "    experiment_name=\"not_impossible\",\n",
    "    rag_type=\"naive_rag\",\n",
    "    model_name=\"llama-3.3-70b-versatile\",\n",
    "    # model_name=\"openai/gpt-oss-120b\",\n",
    "    sample_size=50,\n",
    "    target_rpm=15,                     # Slower for safety (Judge adds calls)\n",
    "    use_llm_judge=False,                # Enable Judge\n",
    "    # judge_model = \"llama-3.3-70b-versatile\"\n",
    "    # judge_model=\"openai/gpt-oss-20b\"\n",
    "    judge_model=\"openai/gpt-oss-120b\" # Pick your judge!\n",
    ")\n",
    "\n",
    "# View the first few rows of the saved data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1849fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 26)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Series([], Name: generated_answer, dtype: object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_not_impossible = pd.read_csv(\"./data/results/eval_not_impossible_naive_rag_20251221_105432.csv\")\n",
    "df_not_impossible.to_csv(\"final_results/NI_naive_rag.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18b3eb0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 26)\n",
      "(10, 26)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>run_id</th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>rag_type</th>\n",
       "      <th>model_name</th>\n",
       "      <th>judge_model</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>question</th>\n",
       "      <th>is_impossible</th>\n",
       "      <th>generated_answer</th>\n",
       "      <th>...</th>\n",
       "      <th>exact_match</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>judge_faithfulness</th>\n",
       "      <th>judge_relevance</th>\n",
       "      <th>judge_utility</th>\n",
       "      <th>judge_coherence</th>\n",
       "      <th>judge_similarity</th>\n",
       "      <th>judge_neg_rejection</th>\n",
       "      <th>judge_reasoning</th>\n",
       "      <th>retrieved_context_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>not_impossible_20251221_105432</td>\n",
       "      <td>not_impossible</td>\n",
       "      <td>naive_rag</td>\n",
       "      <td>llama-3.3-70b-versatile</td>\n",
       "      <td>openai/gpt-oss-120b</td>\n",
       "      <td>20251221_105432</td>\n",
       "      <td>When was the final French and Indian War fought?</td>\n",
       "      <td>False</td>\n",
       "      <td>The French and Indian War was fought from 1754...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The French and Indian War (1754‚Äì1763) was the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>46</td>\n",
       "      <td>not_impossible_20251221_105432</td>\n",
       "      <td>not_impossible</td>\n",
       "      <td>naive_rag</td>\n",
       "      <td>llama-3.3-70b-versatile</td>\n",
       "      <td>openai/gpt-oss-120b</td>\n",
       "      <td>20251221_105432</td>\n",
       "      <td>What was the Union's original war aim?</td>\n",
       "      <td>False</td>\n",
       "      <td>I cannot answer this based on the provided doc...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>American Civil War\\nThe American Civil War was...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>47</td>\n",
       "      <td>not_impossible_20251221_105432</td>\n",
       "      <td>not_impossible</td>\n",
       "      <td>naive_rag</td>\n",
       "      <td>llama-3.3-70b-versatile</td>\n",
       "      <td>openai/gpt-oss-120b</td>\n",
       "      <td>20251221_105432</td>\n",
       "      <td>In what year was it decided that cardinal bish...</td>\n",
       "      <td>False</td>\n",
       "      <td>I cannot answer this based on the provided doc...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Orders and their chief offices\\nCardinal bisho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>not_impossible_20251221_105432</td>\n",
       "      <td>not_impossible</td>\n",
       "      <td>naive_rag</td>\n",
       "      <td>llama-3.3-70b-versatile</td>\n",
       "      <td>openai/gpt-oss-120b</td>\n",
       "      <td>20251221_105432</td>\n",
       "      <td>Hyponatremia is the term that refers to which ...</td>\n",
       "      <td>False</td>\n",
       "      <td>I cannot answer this based on the provided doc...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Homeostasis\\nFor any animal, survival requires...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>49</td>\n",
       "      <td>not_impossible_20251221_105432</td>\n",
       "      <td>not_impossible</td>\n",
       "      <td>naive_rag</td>\n",
       "      <td>llama-3.3-70b-versatile</td>\n",
       "      <td>openai/gpt-oss-120b</td>\n",
       "      <td>20251221_105432</td>\n",
       "      <td>How much of Greece's energy consumption came f...</td>\n",
       "      <td>False</td>\n",
       "      <td>In 2008, renewable energy accounted for 8% of ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1538</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Energy\\nEnergy production in Greece is dominat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0                          run_id experiment_name   rag_type  \\\n",
       "45          45  not_impossible_20251221_105432  not_impossible  naive_rag   \n",
       "46          46  not_impossible_20251221_105432  not_impossible  naive_rag   \n",
       "47          47  not_impossible_20251221_105432  not_impossible  naive_rag   \n",
       "48          48  not_impossible_20251221_105432  not_impossible  naive_rag   \n",
       "49          49  not_impossible_20251221_105432  not_impossible  naive_rag   \n",
       "\n",
       "                 model_name          judge_model        timestamp  \\\n",
       "45  llama-3.3-70b-versatile  openai/gpt-oss-120b  20251221_105432   \n",
       "46  llama-3.3-70b-versatile  openai/gpt-oss-120b  20251221_105432   \n",
       "47  llama-3.3-70b-versatile  openai/gpt-oss-120b  20251221_105432   \n",
       "48  llama-3.3-70b-versatile  openai/gpt-oss-120b  20251221_105432   \n",
       "49  llama-3.3-70b-versatile  openai/gpt-oss-120b  20251221_105432   \n",
       "\n",
       "                                             question  is_impossible  \\\n",
       "45   When was the final French and Indian War fought?          False   \n",
       "46             What was the Union's original war aim?          False   \n",
       "47  In what year was it decided that cardinal bish...          False   \n",
       "48  Hyponatremia is the term that refers to which ...          False   \n",
       "49  How much of Greece's energy consumption came f...          False   \n",
       "\n",
       "                                     generated_answer  ... exact_match  \\\n",
       "45  The French and Indian War was fought from 1754...  ...           0   \n",
       "46  I cannot answer this based on the provided doc...  ...           0   \n",
       "47  I cannot answer this based on the provided doc...  ...           0   \n",
       "48  I cannot answer this based on the provided doc...  ...           0   \n",
       "49  In 2008, renewable energy accounted for 8% of ...  ...           0   \n",
       "\n",
       "   f1_score judge_faithfulness  judge_relevance  judge_utility  \\\n",
       "45   0.0000                0.0              0.0            0.0   \n",
       "46   0.0000                0.0              0.0            0.0   \n",
       "47   0.0000                0.0              0.0            0.0   \n",
       "48   0.0000                0.0              0.0            0.0   \n",
       "49   0.1538                0.0              0.0            0.0   \n",
       "\n",
       "    judge_coherence  judge_similarity  judge_neg_rejection  judge_reasoning  \\\n",
       "45              0.0               0.0                  NaN              NaN   \n",
       "46              0.0               0.0                  NaN              NaN   \n",
       "47              0.0               0.0                  NaN              NaN   \n",
       "48              0.0               0.0                  NaN              NaN   \n",
       "49              0.0               0.0                  NaN              NaN   \n",
       "\n",
       "                               retrieved_context_text  \n",
       "45  The French and Indian War (1754‚Äì1763) was the ...  \n",
       "46  American Civil War\\nThe American Civil War was...  \n",
       "47  Orders and their chief offices\\nCardinal bisho...  \n",
       "48  Homeostasis\\nFor any animal, survival requires...  \n",
       "49  Energy\\nEnergy production in Greece is dominat...  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_path = \"final_results/NI_naive_rag.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "print(df.shape)\n",
    "df[df['generated_answer'].str.contains('Error')]['generated_answer']\n",
    "\n",
    "start = 40\n",
    "end = 50\n",
    "df_batch = df[start:end]\n",
    "print(df_batch.shape)\n",
    "df_batch.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "742bdc14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 26)\n",
      "‚è±Ô∏è  Refining Evaluations | Target RPM: 15 | Model: openai/gpt-oss-120b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Judging: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [05:03<00:00, 30.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving evaluated results to judged/re_evaluated_results_20251222_090259.csv\n",
      "\n",
      "üìä RE-EVALUATION SUMMARY\n",
      "========================================\n",
      "Total                    : 10.0000\n",
      "Avg Faithfulness         : 0.5500\n",
      "Avg Relevance            : 0.6000\n",
      "Avg Context Utility      : 0.7400\n",
      "Avg Coherence            : 0.9900\n",
      "Avg Semantic Similarity  : 0.5000\n",
      "Total API Calls          : 50.0000\n",
      "========================================\n",
      "üíæ Saved: judged/re_evaluated_results_20251222_090259.csv\n",
      "Total                    : 10.0000\n",
      "Avg Faithfulness         : 0.5500\n",
      "Avg Relevance            : 0.6000\n",
      "Avg Context Utility      : 0.7400\n",
      "Avg Coherence            : 0.9900\n",
      "Avg Semantic Similarity  : 0.5000\n",
      "Total API Calls          : 50.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "### LLM AS A JUDGE\n",
    "df_batch = df[start:end]\n",
    "print(df_batch.shape) ### RUN AGAIN\n",
    "\n",
    "# Run the judge\n",
    "df_judged, summary_judged = evaluator.evaluate_batch(\n",
    "    results_path_or_df=df_batch,\n",
    "    judge_model=\"openai/gpt-oss-120b\",\n",
    "    target_rpm = 15\n",
    ")\n",
    "for k, v in summary_judged.items(): print(f\"{k:<25}: {v:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1bbdd627",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: judge_reasoning, dtype: object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df40_50 = pd.read_csv('judged/re_evaluated_results_20251222_090259.csv')\n",
    "df40_50[df40_50['judge_reasoning'].str.contains('Error')]['judge_reasoning']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ee50b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "### WITHOUT IMPOSSIBLE\n",
    "df0_10 = pd.read_csv('judged/re_evaluated_results_20251221_111908.csv')\n",
    "df10_20 = pd.read_csv('judged/re_evaluated_results_20251221_112553.csv')\n",
    "df20_30 = pd.read_csv('judged/re_evaluated_results_20251221_113235.csv')\n",
    "df30_40 = pd.read_csv('judged/re_evaluated_results_20251221_113834.csv')\n",
    "df40_50 = pd.read_csv('judged/re_evaluated_results_20251222_090259.csv')\n",
    "df_final_NI = pd.concat([df0_10, df10_20, df20_30, df30_40, df40_50], ignore_index=True)\n",
    "df_final_NI.to_csv('final_results/NI_naive_rag_judged.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61422cc",
   "metadata": {},
   "source": [
    "## WITH IMPOSSIBLE Questions\n",
    "only 50 samples can be used as its the api limit\n",
    "and it contains the judge eval also"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8417ee4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìö Loaded 142192 validation questions.\n",
      "‚è±Ô∏è Target RPM: 15 | Sleep Base: 4.80s\n",
      "Model: llama-3.3-70b-versatile, Judge: openai/gpt-oss-120b\n",
      "üé≤ Sampling 50 questions...\n",
      "üöÄ Experiment: with_impossible | Judge: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [04:50<00:00,  5.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä EXPERIMENT SUMMARY\n",
      "========================================\n",
      "Total                    : 50.0000\n",
      "Avg F1                   : 0.1293\n",
      "Avg Exact Match          : 0.0600\n",
      "Avg Hit Rate             : 0.7400\n",
      "Avg Faithfulness         : 0.0000\n",
      "Avg Relevance            : 0.0000\n",
      "Avg Context Utility      : 0.0000\n",
      "Avg Coherence            : 0.0000\n",
      "Avg Semantic Similarity  : 0.0000\n",
      "Total API Calls          : 50.0000\n",
      "========================================\n",
      "üíæ Saved: ./data/results/eval_with_impossible_naive_rag_20251222_090410.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>rag_type</th>\n",
       "      <th>model_name</th>\n",
       "      <th>judge_model</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>question</th>\n",
       "      <th>is_impossible</th>\n",
       "      <th>generated_answer</th>\n",
       "      <th>gold_answers</th>\n",
       "      <th>...</th>\n",
       "      <th>exact_match</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>judge_faithfulness</th>\n",
       "      <th>judge_relevance</th>\n",
       "      <th>judge_utility</th>\n",
       "      <th>judge_coherence</th>\n",
       "      <th>judge_similarity</th>\n",
       "      <th>judge_neg_rejection</th>\n",
       "      <th>judge_reasoning</th>\n",
       "      <th>retrieved_context_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>with_impossible_20251222_090410</td>\n",
       "      <td>with_impossible</td>\n",
       "      <td>naive_rag</td>\n",
       "      <td>llama-3.3-70b-versatile</td>\n",
       "      <td>openai/gpt-oss-120b</td>\n",
       "      <td>20251222_090410</td>\n",
       "      <td>How long is the road that connects the largest...</td>\n",
       "      <td>True</td>\n",
       "      <td>I cannot answer this based on the provided doc...</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>Transport\\nSince the 1980s, the road and rail ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>with_impossible_20251222_090410</td>\n",
       "      <td>with_impossible</td>\n",
       "      <td>naive_rag</td>\n",
       "      <td>llama-3.3-70b-versatile</td>\n",
       "      <td>openai/gpt-oss-120b</td>\n",
       "      <td>20251222_090410</td>\n",
       "      <td>When families were trying to ruin their immedi...</td>\n",
       "      <td>True</td>\n",
       "      <td>I cannot answer this based on the provided doc...</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>Endemic species can be threatened with extinct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>with_impossible_20251222_090410</td>\n",
       "      <td>with_impossible</td>\n",
       "      <td>naive_rag</td>\n",
       "      <td>llama-3.3-70b-versatile</td>\n",
       "      <td>openai/gpt-oss-120b</td>\n",
       "      <td>20251222_090410</td>\n",
       "      <td>Who was Wallis Simpson's second husband?</td>\n",
       "      <td>True</td>\n",
       "      <td>I cannot answer this based on the provided doc...</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>As Edward was unmarried and had no children, A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>with_impossible_20251222_090410</td>\n",
       "      <td>with_impossible</td>\n",
       "      <td>naive_rag</td>\n",
       "      <td>llama-3.3-70b-versatile</td>\n",
       "      <td>openai/gpt-oss-120b</td>\n",
       "      <td>20251222_090410</td>\n",
       "      <td>What does 'Pal Monqolica' mean?</td>\n",
       "      <td>True</td>\n",
       "      <td>I cannot answer this based on the provided doc...</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>The Pala Empire (Bengali: ‡¶™‡¶æ‡¶≤ ‡¶∏‡¶æ‡¶Æ‡ßç‡¶∞‡¶æ‡¶ú‡ßç‡¶Ø Pal Sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>with_impossible_20251222_090410</td>\n",
       "      <td>with_impossible</td>\n",
       "      <td>naive_rag</td>\n",
       "      <td>llama-3.3-70b-versatile</td>\n",
       "      <td>openai/gpt-oss-120b</td>\n",
       "      <td>20251222_090410</td>\n",
       "      <td>What was the name of Tancred's nephew?</td>\n",
       "      <td>True</td>\n",
       "      <td>I cannot answer this based on the provided doc...</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>Asclepius is the most famous son of Apollo. Hi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            run_id  experiment_name   rag_type  \\\n",
       "0  with_impossible_20251222_090410  with_impossible  naive_rag   \n",
       "1  with_impossible_20251222_090410  with_impossible  naive_rag   \n",
       "2  with_impossible_20251222_090410  with_impossible  naive_rag   \n",
       "3  with_impossible_20251222_090410  with_impossible  naive_rag   \n",
       "4  with_impossible_20251222_090410  with_impossible  naive_rag   \n",
       "\n",
       "                model_name          judge_model        timestamp  \\\n",
       "0  llama-3.3-70b-versatile  openai/gpt-oss-120b  20251222_090410   \n",
       "1  llama-3.3-70b-versatile  openai/gpt-oss-120b  20251222_090410   \n",
       "2  llama-3.3-70b-versatile  openai/gpt-oss-120b  20251222_090410   \n",
       "3  llama-3.3-70b-versatile  openai/gpt-oss-120b  20251222_090410   \n",
       "4  llama-3.3-70b-versatile  openai/gpt-oss-120b  20251222_090410   \n",
       "\n",
       "                                            question  is_impossible  \\\n",
       "0  How long is the road that connects the largest...           True   \n",
       "1  When families were trying to ruin their immedi...           True   \n",
       "2           Who was Wallis Simpson's second husband?           True   \n",
       "3                    What does 'Pal Monqolica' mean?           True   \n",
       "4             What was the name of Tancred's nephew?           True   \n",
       "\n",
       "                                    generated_answer gold_answers  ...  \\\n",
       "0  I cannot answer this based on the provided doc...           []  ...   \n",
       "1  I cannot answer this based on the provided doc...           []  ...   \n",
       "2  I cannot answer this based on the provided doc...           []  ...   \n",
       "3  I cannot answer this based on the provided doc...           []  ...   \n",
       "4  I cannot answer this based on the provided doc...           []  ...   \n",
       "\n",
       "  exact_match f1_score  judge_faithfulness  judge_relevance  judge_utility  \\\n",
       "0           0      0.0                 0.0              0.0            0.0   \n",
       "1           0      0.0                 0.0              0.0            0.0   \n",
       "2           0      0.0                 0.0              0.0            0.0   \n",
       "3           0      0.0                 0.0              0.0            0.0   \n",
       "4           0      0.0                 0.0              0.0            0.0   \n",
       "\n",
       "   judge_coherence  judge_similarity  judge_neg_rejection  judge_reasoning  \\\n",
       "0              0.0               0.0                  NaN                    \n",
       "1              0.0               0.0                  NaN                    \n",
       "2              0.0               0.0                  NaN                    \n",
       "3              0.0               0.0                  NaN                    \n",
       "4              0.0               0.0                  NaN                    \n",
       "\n",
       "                              retrieved_context_text  \n",
       "0  Transport\\nSince the 1980s, the road and rail ...  \n",
       "1  Endemic species can be threatened with extinct...  \n",
       "2  As Edward was unmarried and had no children, A...  \n",
       "3  The Pala Empire (Bengali: ‡¶™‡¶æ‡¶≤ ‡¶∏‡¶æ‡¶Æ‡ßç‡¶∞‡¶æ‡¶ú‡ßç‡¶Ø Pal Sa...  \n",
       "4  Asclepius is the most famous son of Apollo. Hi...  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### WITH IMPOSSIBLE\n",
    "with open(\"./data/raw/squad_eval_set_all.json\", \"r\") as f:\n",
    "    raw_data = json.load(f)\n",
    "    \n",
    "# Filter only validation data\n",
    "eval_dataset = raw_data\n",
    "# eval_dataset = [x for x in raw_data if x['is_impossible'] == False]\n",
    "# eval_dataset = [x for x in raw_data if x['split'] == 'validation']\n",
    "print(f\"üìö Loaded {len(eval_dataset)} validation questions.\")\n",
    "\n",
    "del raw_data\n",
    "gc.collect()\n",
    "\n",
    "# ==========================================\n",
    "# CELL 3: RUN EXPERIMENT 1 (Baseline)\n",
    "# ==========================================\n",
    "\n",
    "df1, summary = evaluator.run_experiment(\n",
    "    dataset=eval_dataset,\n",
    "    experiment_name=\"with_impossible\",\n",
    "    rag_type=\"naive_rag\",\n",
    "    model_name=\"llama-3.3-70b-versatile\",\n",
    "    # model_name=\"openai/gpt-oss-120b\",\n",
    "    sample_size=50,\n",
    "    target_rpm=15,                     # Slower for safety (Judge adds calls)\n",
    "    use_llm_judge=False,                # Enable Judge\n",
    "    # judge_model = \"llama-3.3-70b-versatile\"\n",
    "    # judge_model=\"openai/gpt-oss-20b\"\n",
    "    judge_model=\"openai/gpt-oss-120b\" \n",
    ")\n",
    "\n",
    "# View the first few rows of the saved data\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48a04be2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: generated_answer, dtype: object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_impossible = pd.read_csv(\"data/results/eval_with_impossible_naive_rag_20251222_090410.csv\")\n",
    "df_impossible.to_csv(\"final_results/Imp_naive_rag.csv\")\n",
    "df_impossible[df_impossible['generated_answer'].str.contains('Error')]['generated_answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b4585241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 26)\n",
      "(10, 26)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>run_id</th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>rag_type</th>\n",
       "      <th>model_name</th>\n",
       "      <th>judge_model</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>question</th>\n",
       "      <th>is_impossible</th>\n",
       "      <th>generated_answer</th>\n",
       "      <th>...</th>\n",
       "      <th>exact_match</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>judge_faithfulness</th>\n",
       "      <th>judge_relevance</th>\n",
       "      <th>judge_utility</th>\n",
       "      <th>judge_coherence</th>\n",
       "      <th>judge_similarity</th>\n",
       "      <th>judge_neg_rejection</th>\n",
       "      <th>judge_reasoning</th>\n",
       "      <th>retrieved_context_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>with_impossible_20251222_090410</td>\n",
       "      <td>with_impossible</td>\n",
       "      <td>naive_rag</td>\n",
       "      <td>llama-3.3-70b-versatile</td>\n",
       "      <td>openai/gpt-oss-120b</td>\n",
       "      <td>20251222_090410</td>\n",
       "      <td>What do reception statutes state is the law of...</td>\n",
       "      <td>False</td>\n",
       "      <td>Reception statutes generally state that the co...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2424</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>American common law\\nThe United States and mos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>with_impossible_20251222_090410</td>\n",
       "      <td>with_impossible</td>\n",
       "      <td>naive_rag</td>\n",
       "      <td>llama-3.3-70b-versatile</td>\n",
       "      <td>openai/gpt-oss-120b</td>\n",
       "      <td>20251222_090410</td>\n",
       "      <td>How many soldiers from Napoleon's army were re...</td>\n",
       "      <td>False</td>\n",
       "      <td>According to Source 3 (Napoleon), 1,500 soldie...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>On 12 June Napoleon led about 124,000 men, kno...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>with_impossible_20251222_090410</td>\n",
       "      <td>with_impossible</td>\n",
       "      <td>naive_rag</td>\n",
       "      <td>llama-3.3-70b-versatile</td>\n",
       "      <td>openai/gpt-oss-120b</td>\n",
       "      <td>20251222_090410</td>\n",
       "      <td>In which area was the 1995 report based?</td>\n",
       "      <td>True</td>\n",
       "      <td>I cannot answer this based on the provided doc...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Oklahoma City is on the I-35 and I-40 corridor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>with_impossible_20251222_090410</td>\n",
       "      <td>with_impossible</td>\n",
       "      <td>naive_rag</td>\n",
       "      <td>llama-3.3-70b-versatile</td>\n",
       "      <td>openai/gpt-oss-120b</td>\n",
       "      <td>20251222_090410</td>\n",
       "      <td>What was created when the interest charged was...</td>\n",
       "      <td>False</td>\n",
       "      <td>I cannot answer this based on the provided doc...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Commercial credit and agricultural consumer lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>with_impossible_20251222_090410</td>\n",
       "      <td>with_impossible</td>\n",
       "      <td>naive_rag</td>\n",
       "      <td>llama-3.3-70b-versatile</td>\n",
       "      <td>openai/gpt-oss-120b</td>\n",
       "      <td>20251222_090410</td>\n",
       "      <td>The mechanical action of what allows insects t...</td>\n",
       "      <td>False</td>\n",
       "      <td>The mechanical action of appendages allows ins...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Insects were the earliest organisms to produce...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0                           run_id  experiment_name   rag_type  \\\n",
       "25          25  with_impossible_20251222_090410  with_impossible  naive_rag   \n",
       "26          26  with_impossible_20251222_090410  with_impossible  naive_rag   \n",
       "27          27  with_impossible_20251222_090410  with_impossible  naive_rag   \n",
       "28          28  with_impossible_20251222_090410  with_impossible  naive_rag   \n",
       "29          29  with_impossible_20251222_090410  with_impossible  naive_rag   \n",
       "\n",
       "                 model_name          judge_model        timestamp  \\\n",
       "25  llama-3.3-70b-versatile  openai/gpt-oss-120b  20251222_090410   \n",
       "26  llama-3.3-70b-versatile  openai/gpt-oss-120b  20251222_090410   \n",
       "27  llama-3.3-70b-versatile  openai/gpt-oss-120b  20251222_090410   \n",
       "28  llama-3.3-70b-versatile  openai/gpt-oss-120b  20251222_090410   \n",
       "29  llama-3.3-70b-versatile  openai/gpt-oss-120b  20251222_090410   \n",
       "\n",
       "                                             question  is_impossible  \\\n",
       "25  What do reception statutes state is the law of...          False   \n",
       "26  How many soldiers from Napoleon's army were re...          False   \n",
       "27           In which area was the 1995 report based?           True   \n",
       "28  What was created when the interest charged was...          False   \n",
       "29  The mechanical action of what allows insects t...          False   \n",
       "\n",
       "                                     generated_answer  ... exact_match  \\\n",
       "25  Reception statutes generally state that the co...  ...           0   \n",
       "26  According to Source 3 (Napoleon), 1,500 soldie...  ...           0   \n",
       "27  I cannot answer this based on the provided doc...  ...           0   \n",
       "28  I cannot answer this based on the provided doc...  ...           0   \n",
       "29  The mechanical action of appendages allows ins...  ...           0   \n",
       "\n",
       "   f1_score judge_faithfulness  judge_relevance  judge_utility  \\\n",
       "25   0.2424                0.0              0.0            0.0   \n",
       "26   0.1429                0.0              0.0            0.0   \n",
       "27   0.0000                0.0              0.0            0.0   \n",
       "28   0.0000                0.0              0.0            0.0   \n",
       "29   0.2000                0.0              0.0            0.0   \n",
       "\n",
       "    judge_coherence  judge_similarity  judge_neg_rejection  judge_reasoning  \\\n",
       "25              0.0               0.0                  NaN              NaN   \n",
       "26              0.0               0.0                  NaN              NaN   \n",
       "27              0.0               0.0                  NaN              NaN   \n",
       "28              0.0               0.0                  NaN              NaN   \n",
       "29              0.0               0.0                  NaN              NaN   \n",
       "\n",
       "                               retrieved_context_text  \n",
       "25  American common law\\nThe United States and mos...  \n",
       "26  On 12 June Napoleon led about 124,000 men, kno...  \n",
       "27  Oklahoma City is on the I-35 and I-40 corridor...  \n",
       "28  Commercial credit and agricultural consumer lo...  \n",
       "29  Insects were the earliest organisms to produce...  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_path = \"final_results/Imp_naive_rag.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "print(df.shape)\n",
    "df[df['generated_answer'].str.contains('Error')]['generated_answer']\n",
    "\n",
    "start = 20\n",
    "end = 30\n",
    "df_batch = df[start:end]\n",
    "print(df_batch.shape)\n",
    "df_batch.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9b4148c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 26)\n",
      "‚è±Ô∏è  Refining Evaluations | Target RPM: 15 | Model: openai/gpt-oss-120b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Judging: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [05:22<00:00, 32.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving evaluated results to judged/re_evaluated_results_20251222_093232.csv\n",
      "\n",
      "üìä RE-EVALUATION SUMMARY\n",
      "========================================\n",
      "Total                    : 10.0000\n",
      "Avg Faithfulness         : 0.5800\n",
      "Avg Relevance            : 0.4200\n",
      "Avg Context Utility      : 0.6100\n",
      "Avg Coherence            : 1.0000\n",
      "Avg Semantic Similarity  : 0.9000\n",
      "Total API Calls          : 54.0000\n",
      "========================================\n",
      "üíæ Saved: judged/re_evaluated_results_20251222_093232.csv\n",
      "Total                    : 10.0000\n",
      "Avg Faithfulness         : 0.5800\n",
      "Avg Relevance            : 0.4200\n",
      "Avg Context Utility      : 0.6100\n",
      "Avg Coherence            : 1.0000\n",
      "Avg Semantic Similarity  : 0.9000\n",
      "Total API Calls          : 54.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "### LLM AS A JUDGE\n",
    "df_batch = df[start:end]\n",
    "print(df_batch.shape) ### RUN AGAIN\n",
    "\n",
    "# Run the judge\n",
    "df_judged, summary_judged = evaluator.evaluate_batch(\n",
    "    results_path_or_df=df_batch,\n",
    "    judge_model=\"openai/gpt-oss-120b\",\n",
    "    target_rpm = 15\n",
    ")\n",
    "for k, v in summary_judged.items(): print(f\"{k:<25}: {v:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "245bdda7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: judge_reasoning, dtype: object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df20_30 = pd.read_csv('judged/re_evaluated_results_20251222_093232.csv')\n",
    "df20_30[df20_30['judge_reasoning'].str.contains('Error')]['judge_reasoning']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0510cda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### WITH IMPOSSIBLE\n",
    "df0_10 = pd.read_csv('judged/re_evaluated_results_20251222_091736.csv')\n",
    "df10_20 = pd.read_csv('judged/re_evaluated_results_20251222_092623.csv')\n",
    "df20_30 = pd.read_csv('judged/re_evaluated_results_20251222_093232.csv')\n",
    "df30_40 = pd.read_csv('')\n",
    "df40_50 = pd.read_csv('')\n",
    "df_final_Imp = pd.concat([df0_10, df10_20, df20_30, df30_40, df40_50], ignore_index=True)\n",
    "df_final_Imp.to_csv('final_results/Imp_naive_rag_judged.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f65e8fc",
   "metadata": {},
   "source": [
    "## COMBINING BOTH FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421cd2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_NI = pd.read_csv('final_results/NI_naive_rag_judged.csv')\n",
    "df_final_Imp = pd.read_csv('final_results/Imp_naive_rag_judged.csv')\n",
    "print(df_final_NI.shape)\n",
    "print(df_final_Imp.shape)\n",
    "df_final = pd.concat([df_final_NI, df_final_Imp], ignore_index=True)\n",
    "print(df_final.shape)\n",
    "df_final.to_csv('final_results/naive_rag_judged.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc89ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "### SUMMARY STATISTICS\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
