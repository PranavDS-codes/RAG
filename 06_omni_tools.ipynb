{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3827a974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Setup Complete.\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# CELL 1: SETUP & CONFIGURATION\n",
    "# ==========================================\n",
    "import json\n",
    "import pickle\n",
    "import os\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import faiss\n",
    "from rank_bm25 import BM25Okapi\n",
    "from sentence_transformers import SentenceTransformer, CrossEncoder\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from typing import List, Dict, Any\n",
    "import unicodedata\n",
    "\n",
    "# --- PATHS ---\n",
    "GRAPH_PATH = \"./models/knowledge_graph.pkl\"\n",
    "CHUNKS_PATH = \"./models/chunk_metadata.pkl\"\n",
    "VECTOR_INDEX_PATH = \"./models/faiss_index.bin\"\n",
    "BM25_INDEX_PATH = \"./models/bm25_index.pkl\"\n",
    "\n",
    "# --- CONFIG ---\n",
    "SUPER_NODE_THRESHOLD = 50\n",
    "GROQ_API_KEY = os.environ.get(\"GROQ_API_KEY\")\n",
    "# MODEL_NAME = \"llama-3.3-70b-versatile\"\n",
    "MODEL_NAME = \"openai/gpt-oss-120b\" \n",
    "\n",
    "# --- FILTERS ---\n",
    "# STOP_RELATIONS = {\n",
    "#     \"is\", \"are\", \"has\", \"have\", \"related_to\", \"part_of\", \"includes\", \n",
    "#     \"involved_in\", \"associated_with\", \"type_of\"\n",
    "# }\n",
    "STOP_RELATIONS = {\"is\", \"are\", \"am\", \"was\", \"were\", \n",
    "    \"has\", \"have\", \"had\", \n",
    "    \"be\", \"been\", \"being\"}\n",
    "\n",
    "STOP_NODES = {\n",
    "    \"it\", \"they\", \"he\", \"she\", \"who\", \"that\", \"this\", \"which\", \n",
    "    \"him\", \"her\", \"them\", \"there\", \"where\"\n",
    "}\n",
    "\n",
    "print(\"‚úÖ Setup Complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0abb74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# CELL 2: ROBUST QUERY OPTIMIZER (AUTO-FIXING)\n",
    "# ==========================================\n",
    "class QueryOptimizer:\n",
    "    def __init__(self, model_name=\"llama-3.3-70b-versatile\", api_key=None):\n",
    "        self.llm = ChatGroq(\n",
    "            temperature=0, \n",
    "            model_name=model_name, \n",
    "            api_key=api_key,\n",
    "            model_kwargs={\"response_format\": {\"type\": \"json_object\"}}\n",
    "        )\n",
    "\n",
    "    def _clean_text(self, text):\n",
    "        \"\"\"Standardizes text to ASCII-compatible format.\"\"\"\n",
    "        if not isinstance(text, str): return text\n",
    "        return unicodedata.normalize('NFKC', text).strip()\n",
    "\n",
    "    def _normalize_response(self, raw_json: Dict) -> Dict:\n",
    "        \"\"\"\n",
    "        ADAPTER: Converts 'Flat' LLM responses into 'Task-Based' structure.\n",
    "        \"\"\"\n",
    "        # Case 1: The LLM followed instructions and gave us \"tasks\"\n",
    "        if \"tasks\" in raw_json and isinstance(raw_json[\"tasks\"], list) and raw_json[\"tasks\"]:\n",
    "            return raw_json\n",
    "\n",
    "        # Case 2: The LLM gave us \"sub_queries\" (The Flat Format)\n",
    "        # We manually construct tasks by distributing the global metadata\n",
    "        if \"sub_queries\" in raw_json and isinstance(raw_json[\"sub_queries\"], list):\n",
    "            print(\"‚ö†Ô∏è Note: LLM returned flat format. Converting to Atomic Tasks...\")\n",
    "            \n",
    "            generated_tasks = []\n",
    "            # Grab global context to share\n",
    "            global_hyde = raw_json.get(\"hyde_passage\", \"\")\n",
    "            global_entities = raw_json.get(\"graph_entities\", [])\n",
    "            global_keywords = raw_json.get(\"keywords\", [])\n",
    "            \n",
    "            for sub_q in raw_json[\"sub_queries\"]:\n",
    "                generated_tasks.append({\n",
    "                    \"sub_query\": sub_q,\n",
    "                    \"hyde_passage\": global_hyde,       # Share the global HyDE\n",
    "                    \"graph_entities\": global_entities, # Share the global Entities\n",
    "                    \"keywords\": global_keywords        # Share the global Keywords\n",
    "                })\n",
    "            \n",
    "            return {\"tasks\": generated_tasks}\n",
    "\n",
    "        # Case 3: Complete Failure (Return empty to trigger fallback)\n",
    "        return {\"tasks\": []}\n",
    "\n",
    "    def optimize(self, query: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Generates a Multi-Task Omni-Query Object.\n",
    "        \"\"\"\n",
    "        system_prompt = \"\"\"\n",
    "            You are the Omni-Query Optimization Engine. Your goal is to transform a raw user question into a high-precision retrieval strategy.\n",
    "\n",
    "            Perform the following analysis steps to generate the output JSON:\n",
    "\n",
    "            1. **DECOMPOSITION (Sub-Queries)**:\n",
    "            - Break the user's query into atomic, self-contained questions.\n",
    "            - Each sub-query must be understandable *without* the original context.\n",
    "            - Cover different angles: factual definitions, comparison, relationships, or procedural steps.\n",
    "\n",
    "            2. **HyDE (Hypothetical Document Embeddings)**:\n",
    "            - Hallucinate a brief, plausible answer passage (3-5 sentences).\n",
    "            - Do NOT worry about factual accuracy; focus on writing the *type* of language, vocabulary, and sentence structure a relevant document would contain.\n",
    "            - Include likely technical terms and domain-specific jargon.\n",
    "\n",
    "            3. **GRAPH ENTITIES (Knowledge Graph)**:\n",
    "            - Extract specific proper nouns, technical concepts, or named entities.\n",
    "            - Focus on subjects that would likely be \"Nodes\" in a Knowledge Graph (e.g., people, organizations, algorithms, chemical compounds).\n",
    "            - Exclude generic nouns like \"pros\", \"cons\", \"features\".\n",
    "\n",
    "            4. **KEYWORDS (BM25 Optimization)**:\n",
    "            - Extract 3-5 high-entropy keywords or short phrases.\n",
    "            - Focus on terms that are unique to this topic (remove stopwords and filler words).\n",
    "            - Include synonyms or alternative spellings if relevant.\n",
    "\n",
    "            **OUTPUT SCHEMA (Strict JSON):**\n",
    "            {\n",
    "                \"sub_queries\": [\"Atomic Question 1\", \"Atomic Question 2\"],\n",
    "                \"hyde_passage\": \"A plausible, dense paragraph containing relevant terminology...\",\n",
    "                \"graph_entities\": [\"Entity1\", \"Entity2\"],\n",
    "                \"keywords\": [\"keyword1\", \"keyword2\", \"synonym\"]\n",
    "            }\n",
    "            \"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = self.llm.invoke([\n",
    "                SystemMessage(content=system_prompt),\n",
    "                HumanMessage(content=query)\n",
    "            ])\n",
    "            raw_result = json.loads(response.content)\n",
    "            \n",
    "            # 1. RUN THE ADAPTER\n",
    "            result = self._normalize_response(raw_result)\n",
    "            \n",
    "            # 2. RUN THE CLEANER\n",
    "            clean_tasks = []\n",
    "            for task in result.get(\"tasks\", []):\n",
    "                clean_tasks.append({\n",
    "                    \"sub_query\": self._clean_text(task.get(\"sub_query\", \"\")),\n",
    "                    \"hyde_passage\": self._clean_text(task.get(\"hyde_passage\", \"\")),\n",
    "                    \"graph_entities\": [self._clean_text(e) for e in task.get(\"graph_entities\", [])],\n",
    "                    \"keywords\": [self._clean_text(k) for k in task.get(\"keywords\", [])]\n",
    "                })\n",
    "            \n",
    "            # 3. Final Check\n",
    "            if not clean_tasks:\n",
    "                raise ValueError(\"Structure empty after normalization\")\n",
    "                \n",
    "            return {\"tasks\": clean_tasks}\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Optimization Failed: {e}\")\n",
    "            # Fallback\n",
    "            return {\n",
    "                \"tasks\": [{\n",
    "                    \"sub_query\": query,\n",
    "                    \"hyde_passage\": query,\n",
    "                    \"graph_entities\": [],\n",
    "                    \"keywords\": query.split()\n",
    "                }]\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b27ee799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Test Search for 'Beyonc√©': Found 543 facts.\n",
      "   Example: Beyonc√© --profiled_at--> AllMusic\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# CELL 3: GRAPH SEARCH MODULE\n",
    "# ==========================================\n",
    "class GraphSearcher:\n",
    "    def __init__(self, graph_path, threshold=50):\n",
    "        with open(graph_path, \"rb\") as f:\n",
    "            self.G = pickle.load(f)\n",
    "        self.node_degrees = dict(self.G.degree())\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def get_neighbors(self, start_node, depth=1):\n",
    "        if start_node not in self.G: return []\n",
    "        facts = set()\n",
    "        queue = [(start_node, 0)]\n",
    "        visited = set()\n",
    "        \n",
    "        while queue:\n",
    "            current, dist = queue.pop(0)\n",
    "            if dist >= depth: continue\n",
    "            visited.add(current)\n",
    "            \n",
    "            # Super-Node Logic\n",
    "            if dist > 0 and self.node_degrees.get(current, 0) > self.threshold:\n",
    "                continue\n",
    "            \n",
    "            for neighbor in self.G.neighbors(current):\n",
    "                if neighbor in visited or neighbor.lower() in STOP_NODES: continue\n",
    "                edge_data = self.G.get_edge_data(current, neighbor)\n",
    "                relation = edge_data.get('relation', 'related_to')\n",
    "                if relation.lower() in STOP_RELATIONS: continue\n",
    "                \n",
    "                facts.add(f\"{current} --{relation}--> {neighbor}\")\n",
    "                queue.append((neighbor, dist + 1))\n",
    "        \n",
    "        return list(facts)\n",
    "\n",
    "graph_engine = GraphSearcher(GRAPH_PATH, threshold=SUPER_NODE_THRESHOLD)\n",
    "# Replace 'Beyonc√©' with a real entity from your graph if needed\n",
    "test_results = graph_engine.get_neighbors(\"Beyonc√©\", depth=1)\n",
    "print(f\"üîç Test Search for 'Beyonc√©': Found {len(test_results)} facts.\")\n",
    "if test_results:\n",
    "    print(f\"   Example: {test_results[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "941ba79f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Loading Resources...\n",
      "üöÄ Omni-Retriever Ready.\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# CELL 4: THE OMNI-RETRIEVER (ATOMIC CONTEXTS)\n",
    "# ==========================================\n",
    "class OmniRetriever:\n",
    "    def __init__(self, graph_path, chunks_path, vector_path, bm25_path, model_name):\n",
    "        # Tools\n",
    "        self.optimizer = QueryOptimizer(api_key=GROQ_API_KEY, model_name=model_name)\n",
    "        self.graph_engine = GraphSearcher(graph_path, threshold=SUPER_NODE_THRESHOLD)\n",
    "        \n",
    "        # Load Resources\n",
    "        print(\"üìÇ Loading Resources...\")\n",
    "        with open(chunks_path, \"rb\") as f:\n",
    "            self.chunks = pickle.load(f)\n",
    "        self.chunk_texts = [c['text'] for c in self.chunks]\n",
    "        \n",
    "        with open(bm25_path, \"rb\") as f:\n",
    "            self.bm25 = pickle.load(f)\n",
    "            \n",
    "        self.embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "        self.index = faiss.read_index(vector_path)\n",
    "        self.reranker = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')\n",
    "        print(\"üöÄ Omni-Retriever Ready.\")\n",
    "\n",
    "    def _retrieve_atomic(self, task, top_k=5, verbose=False):\n",
    "        \"\"\"\n",
    "        Executes search for ONE sub-query and returns its own Top K results.\n",
    "        \"\"\"\n",
    "        candidates = {} # text -> score\n",
    "        \n",
    "        # 1. VECTOR (HyDE)\n",
    "        if task['hyde_passage']:\n",
    "            hyde_emb = self.embedder.encode([task['hyde_passage']], convert_to_numpy=True)\n",
    "            D, I = self.index.search(hyde_emb, k=top_k*2)\n",
    "            for i, idx in enumerate(I[0]):\n",
    "                if idx < len(self.chunks):\n",
    "                    candidates[self.chunks[idx]['text']] = 0.0\n",
    "\n",
    "        # 2. BM25 (Keywords)\n",
    "        bm25_query = f\"{task['sub_query']} {' '.join(task['keywords'])}\"\n",
    "        tokenized_query = bm25_query.split()\n",
    "        bm25_docs = self.bm25.get_top_n(tokenized_query, self.chunk_texts, n=top_k*2)\n",
    "        for txt in bm25_docs:\n",
    "            candidates[txt] = 0.0\n",
    "\n",
    "        # 3. GRAPH (Entities)\n",
    "        graph_facts = []\n",
    "        for entity in task['graph_entities']:\n",
    "            # Exact Match\n",
    "            if entity in self.graph_engine.G:\n",
    "                facts = self.graph_engine.get_neighbors(entity)\n",
    "                graph_facts.extend(facts)\n",
    "            else:\n",
    "                # Fuzzy Fallback\n",
    "                for node in self.graph_engine.G.nodes():\n",
    "                    if str(node).lower() == entity.lower():\n",
    "                        facts = self.graph_engine.get_neighbors(node)\n",
    "                        graph_facts.extend(facts)\n",
    "                        break\n",
    "\n",
    "        for fact in graph_facts[:15]: \n",
    "            candidates[fact] = 0.0\n",
    "            \n",
    "        # 4. RE-RANKING (Per Task)\n",
    "        unique_docs = list(candidates.keys())\n",
    "        if not unique_docs: return []\n",
    "        \n",
    "        pairs = [[task['sub_query'], doc] for doc in unique_docs]\n",
    "        scores = self.reranker.predict(pairs)\n",
    "        \n",
    "        final_ranked = sorted(list(zip(unique_docs, scores)), key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        return final_ranked[:top_k]\n",
    "\n",
    "    def retrieve(self, query, top_k_per_task=5, verbose=True):\n",
    "        # 1. OPTIMIZE\n",
    "        omni = self.optimizer.optimize(query)\n",
    "        \n",
    "        # --- DEBUG CHECK ---\n",
    "        # This prevents the KeyError if something goes wrong\n",
    "        if \"tasks\" not in omni:\n",
    "            print(\"‚ùå Error: Optimizer returned invalid structure:\", omni.keys())\n",
    "            return {\"original_query\": query, \"tasks\": []}\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"\\nüß† OMNI-QUERY: Generated {len(omni['tasks'])} Atomic Tasks\")\n",
    "        \n",
    "        final_structure = {\n",
    "            \"original_query\": query,\n",
    "            \"tasks\": []\n",
    "        }\n",
    "        \n",
    "        # 2. EXECUTE ATOMIC TASKS\n",
    "        for i, task in enumerate(omni['tasks']):\n",
    "            if verbose: \n",
    "                print(f\"\\n‚ö° Executing Task {i+1}: '{task['sub_query']}'\")\n",
    "            \n",
    "            results = self._retrieve_atomic(task, top_k=top_k_per_task, verbose=verbose)\n",
    "            \n",
    "            task_result = {\n",
    "                \"sub_query\": task['sub_query'],\n",
    "                \"results\": results \n",
    "            }\n",
    "            final_structure[\"tasks\"].append(task_result)\n",
    "            \n",
    "            if verbose:\n",
    "                print(f\"   ‚Ü≥ Retrieved {len(results)} contexts (Top Score: {results[0][1]:.4f})\")\n",
    "\n",
    "        return final_structure\n",
    "\n",
    "# Initialize\n",
    "omni_tool = OmniRetriever(GRAPH_PATH, CHUNKS_PATH, VECTOR_INDEX_PATH, BM25_INDEX_PATH, MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "84095335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùì USER QUERY: Who is Beyonce's husband and what companies is she involved with and what is her net worth? When and where was Beyonce born?\n",
      "============================================================\n",
      "‚ö†Ô∏è Note: LLM returned flat format. Converting to Atomic Tasks...\n",
      "\n",
      "üß† OMNI-QUERY: Generated 5 Atomic Tasks\n",
      "\n",
      "‚ö° Executing Task 1: 'Who is Beyonc√©'s husband?'\n",
      "   ‚Ü≥ Retrieved 5 contexts (Top Score: 1.9493)\n",
      "\n",
      "‚ö° Executing Task 2: 'What companies is Beyonc√© involved with?'\n",
      "   ‚Ü≥ Retrieved 5 contexts (Top Score: 6.1093)\n",
      "\n",
      "‚ö° Executing Task 3: 'What is Beyonc√©'s net worth?'\n",
      "   ‚Ü≥ Retrieved 5 contexts (Top Score: 7.9612)\n",
      "\n",
      "‚ö° Executing Task 4: 'When was Beyonc√© born?'\n",
      "   ‚Ü≥ Retrieved 5 contexts (Top Score: 7.4368)\n",
      "\n",
      "‚ö° Executing Task 5: 'Where was Beyonc√© born?'\n",
      "   ‚Ü≥ Retrieved 5 contexts (Top Score: 8.4547)\n",
      "\n",
      "============================================================\n",
      "üèÜ FINAL ATOMIC OUTPUT\n",
      "============================================================\n",
      "\n",
      "üìÇ TASK 1: Who is Beyonc√©'s husband?\n",
      "----------------------------------------\n",
      "   1. [CHUNK] (Score: 1.9493)\n",
      "      Beyonc√© Giselle Knowles-Carter (  bee-ON-say; born September 4, 1981) is an American singer, songwri...\n",
      "   2. [CHUNK] (Score: -0.0542)\n",
      "      Beyonc√© Giselle Knowles was born in Houston, Texas, to Celestine Ann \"Tina\" Knowles (n√©e Beyinc√©), a...\n",
      "   3. [CHUNK] (Score: -1.1106)\n",
      "      Life and career\n",
      "Early life\n",
      "Beyonc√© Giselle Knowles was born in Houston, Texas, on September 4, 1981....\n",
      "   4. [CHUNK] (Score: -1.5113)\n",
      "      On January 7, 2012, Beyonc√© gave birth to a daughter, Blue Ivy Carter, at Lenox Hill Hospital in New...\n",
      "   5. [CHUNK] (Score: -2.0324)\n",
      "      . In 2013, Beyonc√©'s endorsements of Pepsi and H&M made her and Jay Z the world's first billion doll...\n",
      "\n",
      "üìÇ TASK 2: What companies is Beyonc√© involved with?\n",
      "----------------------------------------\n",
      "   1. [CHUNK] (Score: 6.1093)\n",
      "      In October 2014, it was announced that Beyonc√© with her management company Parkwood Entertainment wo...\n",
      "   2. [CHUNK] (Score: 2.3572)\n",
      "      After forming the management company Parkwood Entertainment, Beyonc√© embraced traditional R&B and so...\n",
      "   3. [CHUNK] (Score: 0.0234)\n",
      "      . In 2013, Beyonc√©'s endorsements of Pepsi and H&M made her and Jay Z the world's first billion doll...\n",
      "   4. [CHUNK] (Score: -1.1618)\n",
      "      Beyonc√© Giselle Knowles-Carter (  bee-ON-say; born September 4, 1981) is an American singer, songwri...\n",
      "   5. [CHUNK] (Score: -1.7264)\n",
      "      Beyonc√© Giselle Knowles was born in Houston, Texas, to Celestine Ann \"Tina\" Knowles (n√©e Beyinc√©), a...\n",
      "\n",
      "üìÇ TASK 3: What is Beyonc√©'s net worth?\n",
      "----------------------------------------\n",
      "   1. [CHUNK] (Score: 7.9612)\n",
      "      Wealth\n",
      "Beyonc√© is one of the wealthiest musical artists; as of June 2025, Forbes estimates her net w...\n",
      "   2. [CHUNK] (Score: 7.0143)\n",
      "      . In 2013, Beyonc√©'s endorsements of Pepsi and H&M made her and Jay Z the world's first billion doll...\n",
      "   3. [CHUNK] (Score: -1.5042)\n",
      "      Beyonc√© has received numerous awards. As a solo artist she has sold over 15 million albums in the US...\n",
      "   4. [CHUNK] (Score: -2.0401)\n",
      "      Beyonc√© Giselle Knowles-Carter (  bee-ON-say; born September 4, 1981) is an American singer, songwri...\n",
      "   5. [CHUNK] (Score: -3.1739)\n",
      "      After forming the management company Parkwood Entertainment, Beyonc√© embraced traditional R&B and so...\n",
      "\n",
      "üìÇ TASK 4: When was Beyonc√© born?\n",
      "----------------------------------------\n",
      "   1. [CHUNK] (Score: 7.4368)\n",
      "      Life and career\n",
      "Early life\n",
      "Beyonc√© Giselle Knowles was born in Houston, Texas, on September 4, 1981....\n",
      "   2. [CHUNK] (Score: 6.0982)\n",
      "      Beyonc√© Giselle Knowles-Carter (  bee-ON-say; born September 4, 1981) is an American singer, songwri...\n",
      "   3. [CHUNK] (Score: 4.9054)\n",
      "      Beyonc√© Giselle Knowles was born in Houston, Texas, to Celestine Ann \"Tina\" Knowles (n√©e Beyinc√©), a...\n",
      "   4. [CHUNK] (Score: 1.3327)\n",
      "      On January 7, 2012, Beyonc√© gave birth to a daughter, Blue Ivy Carter, at Lenox Hill Hospital in New...\n",
      "   5. [CHUNK] (Score: 0.6339)\n",
      "      In October 2014, it was announced that Beyonc√© with her management company Parkwood Entertainment wo...\n",
      "\n",
      "üìÇ TASK 5: Where was Beyonc√© born?\n",
      "----------------------------------------\n",
      "   1. [CHUNK] (Score: 8.4547)\n",
      "      Beyonc√© Giselle Knowles was born in Houston, Texas, to Celestine Ann \"Tina\" Knowles (n√©e Beyinc√©), a...\n",
      "   2. [CHUNK] (Score: 7.9841)\n",
      "      Life and career\n",
      "Early life\n",
      "Beyonc√© Giselle Knowles was born in Houston, Texas, on September 4, 1981....\n",
      "   3. [CHUNK] (Score: 3.5066)\n",
      "      Beyonc√© Giselle Knowles-Carter (  bee-ON-say; born September 4, 1981) is an American singer, songwri...\n",
      "   4. [CHUNK] (Score: 1.1838)\n",
      "      In October 2014, it was announced that Beyonc√© with her management company Parkwood Entertainment wo...\n",
      "   5. [CHUNK] (Score: 0.7995)\n",
      "      On January 7, 2012, Beyonc√© gave birth to a daughter, Blue Ivy Carter, at Lenox Hill Hospital in New...\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# CELL 5: ATOMIC RETRIEVAL TEST\n",
    "# ==========================================\n",
    "test_query = \"Who is Beyonce's husband and what companies is she involved with and what is her net worth? When and where was Beyonce born?\"\n",
    "\n",
    "print(f\"‚ùì USER QUERY: {test_query}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# We ask for 3 contexts per sub-task. \n",
    "# Since there are 2 tasks, we expect ~6 total results.\n",
    "output = omni_tool.retrieve(test_query, top_k_per_task=5, verbose=True)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üèÜ FINAL ATOMIC OUTPUT\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for i, task in enumerate(output['tasks']):\n",
    "    print(f\"\\nüìÇ TASK {i+1}: {task['sub_query']}\")\n",
    "    print(\"-\" * 40)\n",
    "    for j, (text, score) in enumerate(task['results']):\n",
    "        tag = \"[GRAPH]\" if \"--\" in text else \"[CHUNK]\"\n",
    "        print(f\"   {j+1}. {tag} (Score: {score:.4f})\")\n",
    "        print(f\"      {text[:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac11167f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Loading Graph from ./models/knowledge_graph.pkl...\n",
      "‚úÖ Graph Loaded. Total Nodes: 98,993\n",
      "\n",
      "==================================================\n",
      "üîé INSPECTING 9 NODES\n",
      "==================================================\n",
      "\n",
      "üéØ Target: 'Jay-Z'\n",
      "   ‚úÖ STATUS: Found (Exact Match)\n",
      "   üìä DEGREE: 16 connections \n",
      "   üîó SAMPLE CONNECTIONS (5 of 10):\n",
      "      ‚Ä¢ --[allegedly_committed]--> infidelity\n",
      "      ‚Ä¢ --[met_with]--> Freddie Gray's family\n",
      "      ‚Ä¢ --[donated_to]--> protesters of Gray's death\n",
      "      ‚Ä¢ --[collaborated_on]--> My Beautiful Dark Twisted Fantasy\n",
      "      ‚Ä¢ --[acquired]--> Aspiro in first quarter 2015\n",
      "\n",
      "üéØ Target: 'Jay Z'\n",
      "   ‚úÖ STATUS: Found (Exact Match)\n",
      "   üìä DEGREE: 10 connections \n",
      "   üîó SAMPLE CONNECTIONS (5 of 8):\n",
      "      ‚Ä¢ --[acquired]--> Aspiro\n",
      "      ‚Ä¢ --[married_to]--> Beyonc√©\n",
      "      ‚Ä¢ --[stated_on]--> March 30, 2015\n",
      "      ‚Ä¢ --[released]--> Glory\n",
      "      ‚Ä¢ --[friends_with]--> Barack Obama\n",
      "\n",
      "üéØ Target: 'Tidal'\n",
      "   ‚úÖ STATUS: Found (Exact Match)\n",
      "   üìä DEGREE: 14 connections \n",
      "   üîó SAMPLE CONNECTIONS (2 of 2):\n",
      "      ‚Ä¢ --[competes_with]--> Spotify\n",
      "      ‚Ä¢ --[announced_on]--> March 30, 2015\n",
      "\n",
      "üéØ Target: 'Roc Nation'\n",
      "   ‚ùå STATUS: Not Found\n",
      "\n",
      "üéØ Target: 'Beyonc√©'\n",
      "   ‚úÖ STATUS: Found (Exact Match)\n",
      "   üìä DEGREE: 585 connections üö® SUPER NODE\n",
      "   üîó SAMPLE CONNECTIONS (5 of 544):\n",
      "      ‚Ä¢ --[born_on]--> September 4, 1981\n",
      "      ‚Ä¢ --[released]--> Dangerously in Love\n",
      "      ‚Ä¢ --[starred_in]--> Dreamgirls\n",
      "      ‚Ä¢ --[influenced_by]--> Jay-Z\n",
      "      ‚Ä¢ --[portrayed]--> Etta James\n",
      "\n",
      "üéØ Target: 'Topshop'\n",
      "   ‚úÖ STATUS: Found (Exact Match)\n",
      "   üìä DEGREE: 2 connections \n",
      "   ‚ö†Ô∏è Dead End (No outgoing connections)\n",
      "\n",
      "üéØ Target: 'United States'\n",
      "   ‚úÖ STATUS: Found (Exact Match)\n",
      "   üìä DEGREE: 625 connections üö® SUPER NODE\n",
      "   üîó SAMPLE CONNECTIONS (5 of 365):\n",
      "      ‚Ä¢ --[shared]--> satellite images with Chinese authorities\n",
      "      ‚Ä¢ --[sent]--> two U.S. Air Force C-17's\n",
      "      ‚Ä¢ --[sent]--> two U.S. Air Force C-17's carrying supplies\n",
      "      ‚Ä¢ --[located_in]--> seventh and eighth grades\n",
      "      ‚Ä¢ --[dominant_use]--> 18 GWth for heating swimming pools as of 2005\n",
      "\n",
      "üéØ Target: '2015'\n",
      "   ‚úÖ STATUS: Found (Fuzzy Match (Found '2015'))\n",
      "   üìä DEGREE: 89 connections üö® SUPER NODE\n",
      "   üîó SAMPLE CONNECTIONS (5 of 14):\n",
      "      ‚Ä¢ --[occurred_in]--> Kanye West won Michael Jackson Video Vanguard Award\n",
      "      ‚Ä¢ --[turnover_amount]--> $31.5 billion per annum\n",
      "      ‚Ä¢ --[year_of]--> Furious 7\n",
      "      ‚Ä¢ --[year_of]--> Jurassic World\n",
      "      ‚Ä¢ --[year_of]--> Minions\n",
      "\n",
      "üéØ Target: '2015'\n",
      "   ‚úÖ STATUS: Found (Exact Match)\n",
      "   üìä DEGREE: 89 connections üö® SUPER NODE\n",
      "   üîó SAMPLE CONNECTIONS (5 of 14):\n",
      "      ‚Ä¢ --[occurred_in]--> Kanye West won Michael Jackson Video Vanguard Award\n",
      "      ‚Ä¢ --[turnover_amount]--> $31.5 billion per annum\n",
      "      ‚Ä¢ --[year_of]--> Furious 7\n",
      "      ‚Ä¢ --[year_of]--> Jurassic World\n",
      "      ‚Ä¢ --[year_of]--> Minions\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# GRAPH NODE INSPECTOR (FIXED)\n",
    "# ==========================================\n",
    "# --- CONFIG ---\n",
    "GRAPH_PATH = \"./models/knowledge_graph.pkl\"\n",
    "SUPER_NODE_THRESHOLD = 50 \n",
    "\n",
    "# --- LOAD GRAPH ---\n",
    "print(f\"üìÇ Loading Graph from {GRAPH_PATH}...\")\n",
    "with open(GRAPH_PATH, \"rb\") as f:\n",
    "    G = pickle.load(f)\n",
    "print(f\"‚úÖ Graph Loaded. Total Nodes: {G.number_of_nodes():,}\")\n",
    "\n",
    "def check_nodes(target_names):\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(f\"üîé INSPECTING {len(target_names)} NODES\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # FIX: Convert node to string before .lower() to handle integers (years, numbers)\n",
    "    node_map = {str(n).lower(): n for n in G.nodes()}\n",
    "    \n",
    "    for name in target_names:\n",
    "        print(f\"\\nüéØ Target: '{name}'\")\n",
    "        \n",
    "        # 1. Exact Match Check\n",
    "        if name in G:\n",
    "            actual_name = name\n",
    "            match_type = \"Exact Match\"\n",
    "        # 2. Case-Insensitive Check\n",
    "        elif str(name).lower() in node_map:\n",
    "            actual_name = node_map[str(name).lower()]\n",
    "            match_type = f\"Fuzzy Match (Found '{actual_name}')\"\n",
    "        else:\n",
    "            print(\"   ‚ùå STATUS: Not Found\")\n",
    "            continue\n",
    "            \n",
    "        # --- GATHER METRICS ---\n",
    "        degree = G.degree[actual_name]\n",
    "        is_super = degree > SUPER_NODE_THRESHOLD\n",
    "        \n",
    "        # Get Sample Neighbors (Outgoing)\n",
    "        neighbors = list(G.neighbors(actual_name))\n",
    "        \n",
    "        # --- DISPLAY ---\n",
    "        print(f\"   ‚úÖ STATUS: Found ({match_type})\")\n",
    "        print(f\"   üìä DEGREE: {degree} connections\", \"üö® SUPER NODE\" if is_super else \"\")\n",
    "        \n",
    "        if neighbors:\n",
    "            print(f\"   üîó SAMPLE CONNECTIONS ({min(5, len(neighbors))} of {len(neighbors)}):\")\n",
    "            for neighbor in neighbors[:5]:\n",
    "                # Get edge relation\n",
    "                edge_data = G.get_edge_data(actual_name, neighbor)\n",
    "                relation = edge_data.get('relation', 'related_to')\n",
    "                print(f\"      ‚Ä¢ --[{relation}]--> {neighbor}\")\n",
    "        else:\n",
    "            print(\"   ‚ö†Ô∏è Dead End (No outgoing connections)\")\n",
    "\n",
    "# ==========================================\n",
    "# ‚ö° EXECUTE SEARCH\n",
    "# ==========================================\n",
    "targets = [\n",
    "    \"Jay-Z\", \n",
    "    \"Jay Z\",      # Fuzzy test\n",
    "    \"Tidal\",\n",
    "    \"Roc Nation\", \n",
    "    \"Beyonc√©\",    \n",
    "    \"Topshop\",\n",
    "    \"United States\",\n",
    "    2015,         # Test integer node\n",
    "    \"2015\"        # Test string representation of integer\n",
    "]\n",
    "\n",
    "check_nodes(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629a14f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
